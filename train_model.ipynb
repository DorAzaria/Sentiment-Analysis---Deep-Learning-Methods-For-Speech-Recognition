{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorAzaria/Sentiment-Analysis-Deep-Learning-Methods-For-Speech-Recognition/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685hzZYY0Oua",
        "outputId": "0841ddb9-ce57-4d90-db7a-4ee55b67893e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/data/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/data/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3h7Ml8w1u_g"
      },
      "source": [
        "# **IMPORTS**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jCj-OhuD1uyS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "import torchaudio\n",
        "from numpy import mat\n",
        "\n",
        "!sudo apt-get install libportaudio2\n",
        "!sudo apt-get install python-scipy\n",
        "\n",
        "!pip install sounddevice\n",
        "!pip install scipy\n",
        "\n",
        "import sounddevice\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS4QYGCi02Y7"
      },
      "source": [
        "# **PREPROCESS**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "820sVvYW1E5o"
      },
      "outputs": [],
      "source": [
        "class Data:\n",
        "\n",
        "    def __init__(self):\n",
        "        file_handler = open('/content/data/MyDrive/dl/dataset.pth', 'rb')\n",
        "        self.data = pickle.load(file_handler)\n",
        "        x_dataset = [embedding[1] for embedding in self.data]\n",
        "        y_dataset = [label[2] for label in self.data]\n",
        "        train_x, test_x, train_y, test_y = train_test_split(np.array(x_dataset), np.array(y_dataset), test_size=0.30)\n",
        "        self.train_x = torch.from_numpy(train_x)\n",
        "        self.train_y = torch.from_numpy(train_y)\n",
        "        torch_train = TensorDataset(self.train_x, self.train_y)\n",
        "        \n",
        "        self.test_x = torch.from_numpy(test_x)\n",
        "        self.test_y = torch.from_numpy(test_y)\n",
        "        torch_test = TensorDataset(self.test_x, self.test_y)\n",
        "        \n",
        "\n",
        "        self.train_loader = DataLoader(torch_train, batch_size=32, drop_last=True, shuffle=True)\n",
        "        self.test_loader = DataLoader(torch_test, batch_size=32, drop_last=True, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9NoyVXt2F_6"
      },
      "source": [
        "# **TRAIN**\n",
        "\n",
        "1, 149, 32\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "56-6NfI62iiW"
      },
      "outputs": [],
      "source": [
        "DROP_OUT = 0.5\n",
        "NUM_OF_CLASSES = 3\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_of_classes, dataset):\n",
        "        super().__init__()\n",
        "\n",
        "        # Hyper parameters\n",
        "        self.epochs = 300\n",
        "        self.batch_size = 32\n",
        "        self.learning_rate = 0.0001\n",
        "        self.dataset = dataset\n",
        "\n",
        "        # Model Architecture\n",
        "        self.first_conv = nn.Conv2d(1, 96, kernel_size=(5, 5), padding=1) # (96, 147, 30)\n",
        "        self.first_bn = nn.BatchNorm2d(96)\n",
        "        self.first_polling = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2)) # (96, 73, 14)\n",
        "\n",
        "        self.second_conv = nn.Conv2d(96, 256, kernel_size=(5, 5), padding=1) # (256, 71, 12)\n",
        "        self.second_bn = nn.BatchNorm2d(256)\n",
        "        self.second_polling = nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1)) # (256, 69, 10)\n",
        "\n",
        "        self.third_conv = nn.Conv2d(256, 384, kernel_size=(3, 3), padding=1) # (384, 69, 10 )\n",
        "        self.third_bn = nn.BatchNorm2d(384)\n",
        "\n",
        "        self.forth_conv = nn.Conv2d(384, 256, kernel_size=(3, 3), padding=1) # (256, 69, 10)\n",
        "        self.forth_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.fifth_conv = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1) # (256, 69, 10)\n",
        "        self.fifth_bn = nn.BatchNorm2d(256)\n",
        "        self.fifth_polling = nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1)) # (256, 68, 9)\n",
        "\n",
        "        self.sixth_conv = nn.Conv2d(256, 64, kernel_size=(2, 2), padding=1) # (64, 69, 10)\n",
        "\n",
        "        self.seventh_conv = nn.Conv2d(64, 64, kernel_size=(3,3), padding=1) # (64, 69, 10)\n",
        "        self.seventh_polling = nn.MaxPool2d(kernel_size=(2,2), stride=(2, 2)) # (64, 34, 5)\n",
        "\n",
        "        self.eighth_conv = nn.Conv2d(64, 32, kernel_size=(3,3), padding=1) # (32, 34, 5)\n",
        "        self.first_drop = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.avg_polling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.first_dense = nn.Linear(32, 1024)\n",
        "        self.second_drop = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.second_dense = nn.Linear(1024, num_of_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        x = nn.ReLU()(self.first_conv(X))\n",
        "        x = self.first_bn(x)\n",
        "        x = self.first_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.second_conv(x))\n",
        "        x = self.second_bn(x)\n",
        "        x = self.second_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.third_conv(x))\n",
        "        x = self.third_bn(x)\n",
        "\n",
        "        x = nn.ReLU()(self.forth_conv(x))\n",
        "        x = self.forth_bn(x)\n",
        "\n",
        "        x = nn.ReLU()(self.fifth_conv(x))\n",
        "        x = self.fifth_bn(x)\n",
        "        x = self.fifth_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.sixth_conv(x))\n",
        "\n",
        "        x = nn.ReLU()(self.seventh_conv(x))\n",
        "        x = self.seventh_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.eighth_conv(x))\n",
        "\n",
        "        x = self.first_drop(x)\n",
        "        x = self.avg_polling(x)\n",
        "\n",
        "        x = x.view(-1, x.shape[1])  # output channel for flatten before entering the dense layer\n",
        "\n",
        "        x = nn.ReLU()(self.first_dense(x))\n",
        "        x = self.second_drop(x)\n",
        "\n",
        "        x = self.second_dense(x)\n",
        "        y = nn.LogSoftmax(dim=1)(x)  # consider using Log-Softmax\n",
        "\n",
        "        return y\n",
        "\n",
        "    def get_epochs(self):\n",
        "        return self.epochs\n",
        "\n",
        "    def get_learning_rate(self):\n",
        "        return self.learning_rate\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batch_size\n",
        "    \n",
        "    def train_model(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n",
        "        # [1904, 928, 2843]\n",
        "        criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.493172268, 3.06357758, 1])).to(device)\n",
        "\n",
        "        n_total_steps = len(self.dataset.train_loader)\n",
        "\n",
        "        for epoch in range(self.get_epochs()):\n",
        "            for i, (embedding, labels) in enumerate(self.dataset.train_loader):\n",
        "\n",
        "                embedding = embedding.type(torch.FloatTensor)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "            \n",
        "                labels = labels.to(device)\n",
        "                embedding = embedding.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.forward(embedding)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                if i == 74:\n",
        "                    print(f'Epoch [{epoch + 1}/{self.epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpaZ7PlR3CRK"
      },
      "source": [
        "# **TEST**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oO0UNKVK2-3S"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "classes = {0: 'positive', 1:'neutral', 2:'negative'}\n",
        "\n",
        "class TestConvNet:\n",
        "    def __init__(self, model, dataset):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.results = []\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            n_correct = 0\n",
        "            n_samples = 0\n",
        "            n_class_correct = [0 for i in range(3)]\n",
        "            n_class_samples = [0 for i in range(3)]\n",
        "            \n",
        "            n_class = [0 for i in range(len(self.dataset.test_y))]\n",
        "            j = 0\n",
        "            \n",
        "            \n",
        "            for embedding, labels in self.dataset.test_loader:\n",
        "                \n",
        "                embedding = embedding.type(torch.FloatTensor)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "                labels = labels.to(device)\n",
        "                embedding = embedding.to(device)\n",
        "                outputs = self.model(embedding)\n",
        "\n",
        "                # max returns (value ,index)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                n_samples += labels.size(0)\n",
        "                n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                for i in range(self.model.batch_size):\n",
        "                    label = labels[i]\n",
        "                    pred = predicted[i]\n",
        "                    if label == pred:\n",
        "                        n_class_correct[label] += 1\n",
        "                    n_class_samples[label] += 1\n",
        "                    n_class[j] = pred.view(-1).detach().cpu().numpy()[0]\n",
        "                    j += 1\n",
        "\n",
        "            acc = 100.0 * n_correct / n_samples\n",
        "            print(f'Accuracy of the network: {acc} %')\n",
        "            self.results.append(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "            for i in range(3):\n",
        "                acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "                print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "                self.results.append(f'Accuracy of {classes[i]}: {acc} %')\n",
        "            \n",
        "            return n_class\n",
        "        # saved_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
        "        # file_name = 'result.txt'\n",
        "        # directory = '/content/data/' + str(saved_time)\n",
        "        # os.mkdir(directory)\n",
        "\n",
        "        # with open(directory + \"/\" + file_name, 'w') as f:\n",
        "        #     for line in self.results:\n",
        "        #         f.write(line)\n",
        "        #         f.write('\\n')\n",
        "\n",
        "        # torch.save(self.model, directory + \"/model.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbdGGMiq35tS"
      },
      "source": [
        "# **Main**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McQMhz2iXxNQ"
      },
      "source": [
        "## NORM AND INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sj2SqEan3-Gz"
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "model = bundle.get_model().to(device)\n",
        "\n",
        "\n",
        "def inference(file_name):\n",
        "    SAMPLE_RATE = 16000\n",
        "    waveform, sample_rate = torchaudio.load(filepath=file_name,  num_frames=SAMPLE_RATE * 3)\n",
        "    waveform = waveform.view(1, 96000)\n",
        "    waveform = waveform.to(device)\n",
        "    \n",
        "    if (len(waveform[0]) < 48000):\n",
        "        print(f'less than 3 seconds: {file_name}')\n",
        "\n",
        "    if sample_rate != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        embedding, _ = model(waveform)\n",
        "\n",
        "    return embedding.unsqueeze(0)\n",
        "\n",
        "\n",
        "def Norm(X):\n",
        "    embedding = X.detach().cpu().numpy()\n",
        "    for i in range(len(embedding)):\n",
        "        mlist = embedding[0][i]\n",
        "        embedding[0][i] = 2 * (mlist - np.max(mlist)) / (np.max(mlist) - np.min(mlist)) + 1\n",
        "\n",
        "    return torch.from_numpy(embedding).to(device)\n",
        "\n",
        "\n",
        "def recording(name):\n",
        "    # import sounddevice\n",
        "    # # from scipy.io.wavefile import write\n",
        "    # filename = name\n",
        "    # fps = 16000\n",
        "    # duration = 3\n",
        "    # print(\"Recording ..\")\n",
        "    # recording = sounddevice.rec(int(duration * fps), samplerate = fps, channels = 2)\n",
        "    # sounddevice.wait()\n",
        "    # print(\"Done.\")\n",
        "    # write(filename, fps, recording)\n",
        "    # return filename + \".wav\"\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCDZ2CSE4Mit"
      },
      "source": [
        "## START TRAIN\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOYlypNI4RD2",
        "outputId": "a7dfa345-626c-418d-a0b4-d42cde378a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/300], Loss: 1.0691\n",
            "Epoch [2/300], Loss: 0.9429\n",
            "Epoch [3/300], Loss: 0.9200\n",
            "Epoch [4/300], Loss: 0.8297\n",
            "Epoch [5/300], Loss: 0.7376\n",
            "Epoch [6/300], Loss: 0.7687\n",
            "Epoch [7/300], Loss: 0.8963\n",
            "Epoch [8/300], Loss: 0.7148\n",
            "Epoch [9/300], Loss: 0.7555\n",
            "Epoch [10/300], Loss: 0.6120\n",
            "Epoch [11/300], Loss: 0.6654\n",
            "Epoch [12/300], Loss: 0.8438\n",
            "Epoch [13/300], Loss: 0.7070\n",
            "Epoch [14/300], Loss: 0.5147\n",
            "Epoch [15/300], Loss: 0.6078\n",
            "Epoch [16/300], Loss: 0.5095\n",
            "Epoch [17/300], Loss: 0.3870\n",
            "Epoch [18/300], Loss: 0.5265\n",
            "Epoch [19/300], Loss: 0.4660\n",
            "Epoch [20/300], Loss: 0.2961\n",
            "Epoch [21/300], Loss: 0.4877\n",
            "Epoch [22/300], Loss: 0.2932\n",
            "Epoch [23/300], Loss: 0.3868\n",
            "Epoch [24/300], Loss: 0.2014\n",
            "Epoch [25/300], Loss: 0.1674\n",
            "Epoch [26/300], Loss: 0.3186\n",
            "Epoch [27/300], Loss: 0.2247\n",
            "Epoch [28/300], Loss: 0.2272\n",
            "Epoch [29/300], Loss: 0.2745\n",
            "Epoch [30/300], Loss: 0.3118\n",
            "Epoch [31/300], Loss: 0.4622\n",
            "Epoch [32/300], Loss: 0.1485\n",
            "Epoch [33/300], Loss: 0.3633\n",
            "Epoch [34/300], Loss: 0.3355\n",
            "Epoch [35/300], Loss: 0.1920\n",
            "Epoch [36/300], Loss: 0.2956\n",
            "Epoch [37/300], Loss: 0.1208\n",
            "Epoch [38/300], Loss: 0.2083\n",
            "Epoch [39/300], Loss: 0.2273\n",
            "Epoch [40/300], Loss: 0.2283\n",
            "Epoch [41/300], Loss: 0.1858\n",
            "Epoch [42/300], Loss: 0.1886\n",
            "Epoch [43/300], Loss: 0.3089\n",
            "Epoch [44/300], Loss: 0.2147\n",
            "Epoch [45/300], Loss: 0.2347\n",
            "Epoch [46/300], Loss: 0.2928\n",
            "Epoch [47/300], Loss: 0.3861\n",
            "Epoch [48/300], Loss: 0.1794\n",
            "Epoch [49/300], Loss: 0.2352\n",
            "Epoch [50/300], Loss: 0.3069\n",
            "Epoch [51/300], Loss: 0.4036\n",
            "Epoch [52/300], Loss: 0.1864\n",
            "Epoch [53/300], Loss: 0.2042\n",
            "Epoch [54/300], Loss: 0.2149\n",
            "Epoch [55/300], Loss: 0.3916\n",
            "Epoch [56/300], Loss: 0.1645\n",
            "Epoch [57/300], Loss: 0.2605\n",
            "Epoch [58/300], Loss: 0.3673\n",
            "Epoch [59/300], Loss: 0.0838\n",
            "Epoch [60/300], Loss: 0.3386\n",
            "Epoch [61/300], Loss: 0.1709\n",
            "Epoch [62/300], Loss: 0.3722\n",
            "Epoch [63/300], Loss: 0.3004\n",
            "Epoch [64/300], Loss: 0.1321\n",
            "Epoch [65/300], Loss: 0.3398\n",
            "Epoch [66/300], Loss: 0.0905\n",
            "Epoch [67/300], Loss: 0.3526\n",
            "Epoch [68/300], Loss: 0.1753\n",
            "Epoch [69/300], Loss: 0.2440\n",
            "Epoch [70/300], Loss: 0.2140\n",
            "Epoch [71/300], Loss: 0.1902\n",
            "Epoch [72/300], Loss: 0.3774\n",
            "Epoch [73/300], Loss: 0.2955\n",
            "Epoch [74/300], Loss: 0.2274\n",
            "Epoch [75/300], Loss: 0.2550\n",
            "Epoch [76/300], Loss: 0.1804\n",
            "Epoch [77/300], Loss: 0.3727\n",
            "Epoch [78/300], Loss: 0.1267\n",
            "Epoch [79/300], Loss: 0.1832\n",
            "Epoch [80/300], Loss: 0.3826\n",
            "Epoch [81/300], Loss: 0.0962\n",
            "Epoch [82/300], Loss: 0.1449\n",
            "Epoch [83/300], Loss: 0.2296\n",
            "Epoch [84/300], Loss: 0.2522\n",
            "Epoch [85/300], Loss: 0.1420\n",
            "Epoch [86/300], Loss: 0.0598\n",
            "Epoch [87/300], Loss: 0.2081\n",
            "Epoch [88/300], Loss: 0.2231\n",
            "Epoch [89/300], Loss: 0.2077\n",
            "Epoch [90/300], Loss: 0.1074\n",
            "Epoch [91/300], Loss: 0.2005\n",
            "Epoch [92/300], Loss: 0.1177\n",
            "Epoch [93/300], Loss: 0.1681\n",
            "Epoch [94/300], Loss: 0.2217\n",
            "Epoch [95/300], Loss: 0.1269\n",
            "Epoch [96/300], Loss: 0.1383\n",
            "Epoch [97/300], Loss: 0.0601\n",
            "Epoch [98/300], Loss: 0.0427\n",
            "Epoch [99/300], Loss: 0.1698\n",
            "Epoch [100/300], Loss: 0.2689\n",
            "Epoch [101/300], Loss: 0.0984\n",
            "Epoch [102/300], Loss: 0.3269\n",
            "Epoch [103/300], Loss: 0.2413\n",
            "Epoch [104/300], Loss: 0.2396\n",
            "Epoch [105/300], Loss: 0.1369\n",
            "Epoch [106/300], Loss: 0.1595\n",
            "Epoch [107/300], Loss: 0.1691\n",
            "Epoch [108/300], Loss: 0.0704\n",
            "Epoch [109/300], Loss: 0.0591\n",
            "Epoch [110/300], Loss: 0.2964\n",
            "Epoch [111/300], Loss: 0.1001\n",
            "Epoch [112/300], Loss: 0.2122\n",
            "Epoch [113/300], Loss: 0.0731\n",
            "Epoch [114/300], Loss: 0.2338\n",
            "Epoch [115/300], Loss: 0.0968\n",
            "Epoch [116/300], Loss: 0.1377\n",
            "Epoch [117/300], Loss: 0.1463\n",
            "Epoch [118/300], Loss: 0.3395\n",
            "Epoch [119/300], Loss: 0.0536\n",
            "Epoch [120/300], Loss: 0.1000\n",
            "Epoch [121/300], Loss: 0.0579\n",
            "Epoch [122/300], Loss: 0.0879\n",
            "Epoch [123/300], Loss: 0.1505\n",
            "Epoch [124/300], Loss: 0.0278\n",
            "Epoch [125/300], Loss: 0.1525\n",
            "Epoch [126/300], Loss: 0.1376\n",
            "Epoch [127/300], Loss: 0.0626\n",
            "Epoch [129/300], Loss: 0.1341\n",
            "Epoch [130/300], Loss: 0.1087\n",
            "Epoch [131/300], Loss: 0.1333\n",
            "Epoch [132/300], Loss: 0.0328\n",
            "Epoch [133/300], Loss: 0.1293\n",
            "Epoch [134/300], Loss: 0.0493\n",
            "Epoch [135/300], Loss: 0.0482\n",
            "Epoch [136/300], Loss: 0.0804\n",
            "Epoch [137/300], Loss: 0.0962\n",
            "Epoch [138/300], Loss: 0.0853\n",
            "Epoch [139/300], Loss: 0.1114\n",
            "Epoch [140/300], Loss: 0.0704\n",
            "Epoch [141/300], Loss: 0.0974\n",
            "Epoch [142/300], Loss: 0.0654\n",
            "Epoch [143/300], Loss: 0.0526\n",
            "Epoch [144/300], Loss: 0.0142\n",
            "Epoch [145/300], Loss: 0.0309\n",
            "Epoch [146/300], Loss: 0.2934\n",
            "Epoch [147/300], Loss: 0.0307\n",
            "Epoch [148/300], Loss: 0.0128\n",
            "Epoch [149/300], Loss: 0.0857\n",
            "Epoch [150/300], Loss: 0.0241\n",
            "Epoch [151/300], Loss: 0.0735\n",
            "Epoch [152/300], Loss: 0.0900\n",
            "Epoch [153/300], Loss: 0.0430\n",
            "Epoch [154/300], Loss: 0.0291\n",
            "Epoch [155/300], Loss: 0.3796\n",
            "Epoch [156/300], Loss: 0.0267\n",
            "Epoch [157/300], Loss: 0.0093\n",
            "Epoch [158/300], Loss: 0.0562\n",
            "Epoch [159/300], Loss: 0.0162\n",
            "Epoch [160/300], Loss: 0.0252\n",
            "Epoch [161/300], Loss: 0.0947\n",
            "Epoch [162/300], Loss: 0.0281\n",
            "Epoch [163/300], Loss: 0.0065\n",
            "Epoch [164/300], Loss: 0.0781\n",
            "Epoch [165/300], Loss: 0.0197\n",
            "Epoch [166/300], Loss: 0.1113\n",
            "Epoch [167/300], Loss: 0.0578\n",
            "Epoch [168/300], Loss: 0.0122\n",
            "Epoch [169/300], Loss: 0.3227\n",
            "Epoch [170/300], Loss: 0.3652\n",
            "Epoch [171/300], Loss: 0.0162\n",
            "Epoch [172/300], Loss: 0.0050\n",
            "Epoch [173/300], Loss: 0.0315\n",
            "Epoch [174/300], Loss: 0.0602\n",
            "Epoch [175/300], Loss: 0.3888\n",
            "Epoch [176/300], Loss: 0.1204\n",
            "Epoch [177/300], Loss: 0.0763\n",
            "Epoch [178/300], Loss: 0.0504\n",
            "Epoch [179/300], Loss: 0.0060\n",
            "Epoch [180/300], Loss: 0.0157\n",
            "Epoch [181/300], Loss: 0.0117\n",
            "Epoch [182/300], Loss: 0.0050\n",
            "Epoch [183/300], Loss: 0.1433\n",
            "Epoch [184/300], Loss: 0.1034\n",
            "Epoch [185/300], Loss: 0.1575\n",
            "Epoch [186/300], Loss: 0.1507\n",
            "Epoch [187/300], Loss: 0.1563\n",
            "Epoch [188/300], Loss: 0.0305\n",
            "Epoch [189/300], Loss: 0.0058\n",
            "Epoch [190/300], Loss: 0.0571\n",
            "Epoch [191/300], Loss: 0.0207\n",
            "Epoch [192/300], Loss: 0.0738\n",
            "Epoch [193/300], Loss: 0.0691\n",
            "Epoch [194/300], Loss: 0.0363\n",
            "Epoch [195/300], Loss: 0.0007\n",
            "Epoch [196/300], Loss: 0.0931\n",
            "Epoch [197/300], Loss: 0.0013\n",
            "Epoch [198/300], Loss: 0.0466\n",
            "Epoch [199/300], Loss: 0.0167\n",
            "Epoch [200/300], Loss: 0.0380\n",
            "Epoch [201/300], Loss: 0.0504\n",
            "Epoch [202/300], Loss: 0.0808\n",
            "Epoch [203/300], Loss: 0.2359\n",
            "Epoch [204/300], Loss: 0.0623\n",
            "Epoch [205/300], Loss: 0.0036\n",
            "Epoch [206/300], Loss: 0.0060\n",
            "Epoch [207/300], Loss: 0.0779\n",
            "Epoch [208/300], Loss: 0.1833\n",
            "Epoch [209/300], Loss: 0.0303\n",
            "Epoch [210/300], Loss: 0.0554\n",
            "Epoch [211/300], Loss: 0.0508\n",
            "Epoch [212/300], Loss: 0.1122\n",
            "Epoch [213/300], Loss: 0.0238\n",
            "Epoch [214/300], Loss: 0.0597\n",
            "Epoch [215/300], Loss: 0.0163\n",
            "Epoch [216/300], Loss: 0.0095\n",
            "Epoch [217/300], Loss: 0.0296\n",
            "Epoch [218/300], Loss: 0.1607\n",
            "Epoch [219/300], Loss: 0.0558\n",
            "Epoch [220/300], Loss: 0.0045\n",
            "Epoch [221/300], Loss: 0.1446\n",
            "Epoch [222/300], Loss: 0.0411\n",
            "Epoch [223/300], Loss: 0.0023\n",
            "Epoch [224/300], Loss: 0.0306\n",
            "Epoch [225/300], Loss: 0.0134\n",
            "Epoch [226/300], Loss: 0.0439\n",
            "Epoch [227/300], Loss: 0.0851\n",
            "Epoch [228/300], Loss: 0.0180\n",
            "Epoch [229/300], Loss: 0.0285\n",
            "Epoch [230/300], Loss: 0.1193\n",
            "Epoch [231/300], Loss: 0.0457\n",
            "Epoch [232/300], Loss: 0.0112\n",
            "Epoch [233/300], Loss: 0.0121\n",
            "Epoch [234/300], Loss: 0.1218\n",
            "Epoch [235/300], Loss: 0.0053\n",
            "Epoch [236/300], Loss: 0.0016\n",
            "Epoch [237/300], Loss: 0.1302\n",
            "Epoch [238/300], Loss: 0.0256\n",
            "Epoch [239/300], Loss: 0.0256\n",
            "Epoch [240/300], Loss: 0.0523\n",
            "Epoch [241/300], Loss: 0.0781\n",
            "Epoch [242/300], Loss: 0.0232\n",
            "Epoch [243/300], Loss: 0.0048\n",
            "Epoch [244/300], Loss: 0.0189\n",
            "Epoch [245/300], Loss: 0.1495\n",
            "Epoch [246/300], Loss: 0.0014\n",
            "Epoch [247/300], Loss: 0.0576\n",
            "Epoch [248/300], Loss: 0.0373\n",
            "Epoch [249/300], Loss: 0.0178\n",
            "Epoch [250/300], Loss: 0.0110\n",
            "Epoch [251/300], Loss: 0.0122\n",
            "Epoch [252/300], Loss: 0.0022\n",
            "Epoch [253/300], Loss: 0.0037\n",
            "Epoch [254/300], Loss: 0.0251\n",
            "Epoch [255/300], Loss: 0.0725\n",
            "Epoch [256/300], Loss: 0.0377\n",
            "Epoch [257/300], Loss: 0.0125\n",
            "Epoch [258/300], Loss: 0.0313\n",
            "Epoch [259/300], Loss: 0.0058\n",
            "Epoch [260/300], Loss: 0.0073\n",
            "Epoch [261/300], Loss: 0.0578\n",
            "Epoch [262/300], Loss: 0.0016\n",
            "Epoch [263/300], Loss: 0.0381\n",
            "Epoch [264/300], Loss: 0.0596\n",
            "Epoch [265/300], Loss: 0.0054\n",
            "Epoch [266/300], Loss: 0.0020\n",
            "Epoch [267/300], Loss: 0.0192\n",
            "Epoch [268/300], Loss: 0.0373\n",
            "Epoch [269/300], Loss: 0.0113\n",
            "Epoch [270/300], Loss: 0.0032\n",
            "Epoch [271/300], Loss: 0.0956\n",
            "Epoch [272/300], Loss: 0.0111\n",
            "Epoch [273/300], Loss: 0.0352\n",
            "Epoch [274/300], Loss: 0.0323\n",
            "Epoch [275/300], Loss: 0.1473\n",
            "Epoch [276/300], Loss: 0.0138\n",
            "Epoch [277/300], Loss: 0.0579\n",
            "Epoch [278/300], Loss: 0.0348\n",
            "Epoch [279/300], Loss: 0.0780\n",
            "Epoch [280/300], Loss: 0.0227\n",
            "Epoch [281/300], Loss: 0.0303\n",
            "Epoch [282/300], Loss: 0.0032\n",
            "Epoch [283/300], Loss: 0.0654\n",
            "Epoch [284/300], Loss: 0.0469\n",
            "Epoch [285/300], Loss: 0.0142\n",
            "Epoch [286/300], Loss: 0.0538\n",
            "Epoch [287/300], Loss: 0.0077\n",
            "Epoch [288/300], Loss: 0.0128\n",
            "Epoch [289/300], Loss: 0.0848\n",
            "Epoch [290/300], Loss: 0.0021\n",
            "Epoch [291/300], Loss: 0.0156\n",
            "Epoch [292/300], Loss: 0.0014\n",
            "Epoch [293/300], Loss: 0.0016\n",
            "Epoch [294/300], Loss: 0.0278\n",
            "Epoch [295/300], Loss: 0.0089\n",
            "Epoch [296/300], Loss: 0.0357\n",
            "Epoch [297/300], Loss: 0.0051\n",
            "Epoch [298/300], Loss: 0.0821\n",
            "Epoch [299/300], Loss: 0.0788\n",
            "Epoch [300/300], Loss: 0.0356\n"
          ]
        }
      ],
      "source": [
        "aer_dataset = Data()\n",
        "cnn = ConvNet(3, aer_dataset)\n",
        "cnn.to(device)\n",
        "cnn.train_model()\n",
        "torch.save(cnn, \"/model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn, \"/content/data/MyDrive/dl/model.pth\")"
      ],
      "metadata": {
        "id": "JEZvqhOZbHFl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTWNPkZ04UCp"
      },
      "source": [
        "## START TEST\n",
        "\n",
        "\n",
        "Accuracy of the network: 70.1171875 %\n",
        "\n",
        "Accuracy of positive: 63.80597014925373 %\n",
        "\n",
        "Accuracy of neutral: 55.367231638418076 %\n",
        "\n",
        "Accuracy of negative: 77.54749568221071 %\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md2c1Cu8n2Wv",
        "outputId": "9703bd29-bf11-4992-ca03-e42bf331158a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network: 70.10613207547169 %\n",
            "Accuracy of positive: 74.17677642980937 %\n",
            "Accuracy of neutral: 56.81818181818182 %\n",
            "Accuracy of negative: 71.46198830409357 %\n"
          ]
        }
      ],
      "source": [
        "test = TestConvNet(cnn, aer_dataset)\n",
        "n_class = test.test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Display the confusion matrix as a heatmap\n",
        "arr = confusion_matrix(aer_dataset.test_y.detach().cpu().numpy(), n_class)\n",
        "class_names = ['Positive', 'Neutral', ' Negative']\n",
        "print(arr)\n",
        "df_cm = pd.DataFrame(arr, class_names, class_names)\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='BuGn')\n",
        "plt.xlabel(\"prediction\")\n",
        "plt.ylabel(\"label (ground truth)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "b3Ok6cs_J9K_",
        "outputId": "a1448a24-0b23-4e3d-b174-f45b3370352d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[430  35 114]\n",
            " [ 55 150  60]\n",
            " [191  57 611]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awUU1AREn3fk"
      },
      "source": [
        "## INFERENCE\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH-sKsHj4ZwS",
        "outputId": "5580a798-845c-454d-fd2f-34051269c239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([9.4223136e-01, 2.0397495e-09, 5.7768621e-02], dtype=float32)]\n",
            "positive\n"
          ]
        }
      ],
      "source": [
        "inf_X = inference('/content/data/MyDrive/dl/angry2.wav')\n",
        "X = Norm(inf_X)\n",
        "y = cnn.forward(X)\n",
        "y = y.cpu().detach().numpy()\n",
        "predict = [np.exp(c) for c in y]\n",
        "max = np.argmax(predict)\n",
        "print(predict)\n",
        "print(classes[max])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "train_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}