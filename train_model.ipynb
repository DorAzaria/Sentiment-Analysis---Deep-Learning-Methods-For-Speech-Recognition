{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorAzaria/Sentiment-Analysis-Deep-Learning-Methods-For-Speech-Recognition/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685hzZYY0Oua",
        "outputId": "faed7661-cb80-4e96-9d90-17720b6582e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/data/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/data/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3h7Ml8w1u_g"
      },
      "source": [
        "# **IMPORTS**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jCj-OhuD1uyS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "import torchaudio\n",
        "from numpy import mat\n",
        "\n",
        "!sudo apt-get install libportaudio2\n",
        "!sudo apt-get install python-scipy\n",
        "\n",
        "!pip install sounddevice\n",
        "!pip install scipy\n",
        "\n",
        "import sounddevice\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS4QYGCi02Y7"
      },
      "source": [
        "# **PREPROCESS**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "820sVvYW1E5o"
      },
      "outputs": [],
      "source": [
        "class Data:\n",
        "\n",
        "    def __init__(self):\n",
        "        file_handler = open('/content/data/MyDrive/dl/dataset.pth', 'rb')\n",
        "        data = pickle.load(file_handler)\n",
        "        x_dataset = [embedding[1] for embedding in data]\n",
        "        y_dataset = [label[2] for label in data]\n",
        "        train_x, test_x, train_y, test_y = train_test_split(np.array(x_dataset), np.array(y_dataset), test_size=0.30)\n",
        "        self.train_x = torch.from_numpy(train_x)\n",
        "        self.train_y = torch.from_numpy(train_y)\n",
        "        torch_train = TensorDataset(self.train_x, self.train_y)\n",
        "        \n",
        "        self.test_x = torch.from_numpy(test_x)\n",
        "        self.test_y = torch.from_numpy(test_y)\n",
        "        torch_test = TensorDataset(self.test_x, self.test_y)\n",
        "        \n",
        "\n",
        "        self.train_loader = DataLoader(torch_train, batch_size=32, drop_last=True, shuffle=True)\n",
        "        self.test_loader = DataLoader(torch_test, batch_size=32, drop_last=True, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9NoyVXt2F_6"
      },
      "source": [
        "# **TRAIN**\n",
        "\n",
        "1, 149, 32\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "56-6NfI62iiW"
      },
      "outputs": [],
      "source": [
        "DROP_OUT = 0.5\n",
        "NUM_OF_CLASSES = 3\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_of_classes, dataset):\n",
        "        super().__init__()\n",
        "\n",
        "        # Hyper parameters\n",
        "        self.epochs = 10\n",
        "        self.batch_size = 32\n",
        "        self.learning_rate = 0.0001\n",
        "        self.dataset = dataset\n",
        "\n",
        "        # Model Architecture\n",
        "        self.first_conv = nn.Conv2d(1, 96, kernel_size=(5, 5), padding=1) # (96, 147, 30)\n",
        "        self.first_bn = nn.BatchNorm2d(96)\n",
        "        self.first_polling = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2)) # (96, 73, 14)\n",
        "\n",
        "        self.second_conv = nn.Conv2d(96, 256, kernel_size=(5, 5), padding=1) # (256, 71, 12)\n",
        "        self.second_bn = nn.BatchNorm2d(256)\n",
        "        self.second_polling = nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1)) # (256, 69, 10)\n",
        "\n",
        "        self.third_conv = nn.Conv2d(256, 384, kernel_size=(3, 3), padding=1) # (384, 69, 10 )\n",
        "        self.third_bn = nn.BatchNorm2d(384)\n",
        "\n",
        "        self.forth_conv = nn.Conv2d(384, 256, kernel_size=(3, 3), padding=1) # (256, 69, 10)\n",
        "        self.forth_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.fifth_conv = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1) # (256, 69, 10)\n",
        "        self.fifth_bn = nn.BatchNorm2d(256)\n",
        "        self.fifth_polling = nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1)) # (256, 68, 9)\n",
        "\n",
        "        self.sixth_conv = nn.Conv2d(256, 64, kernel_size=(2, 2), padding=1) # (64, 69, 10)\n",
        "\n",
        "        self.seventh_conv = nn.Conv2d(64, 64, kernel_size=(3,3), padding=1) # (64, 69, 10)\n",
        "        self.seventh_polling = nn.MaxPool2d(kernel_size=(2,2), stride=(2, 2)) # (64, 34, 5)\n",
        "\n",
        "        self.eighth_conv = nn.Conv2d(64, 32, kernel_size=(3,3), padding=1) # (32, 34, 5)\n",
        "        self.first_drop = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.avg_polling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.first_dense = nn.Linear(32, 1024)\n",
        "        self.second_drop = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.second_dense = nn.Linear(1024, num_of_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        x = nn.ReLU()(self.first_conv(X))\n",
        "        x = self.first_bn(x)\n",
        "        x = self.first_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.second_conv(x))\n",
        "        x = self.second_bn(x)\n",
        "        x = self.second_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.third_conv(x))\n",
        "        x = self.third_bn(x)\n",
        "\n",
        "        x = nn.ReLU()(self.forth_conv(x))\n",
        "        x = self.forth_bn(x)\n",
        "\n",
        "        x = nn.ReLU()(self.fifth_conv(x))\n",
        "        x = self.fifth_bn(x)\n",
        "        x = self.fifth_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.sixth_conv(x))\n",
        "\n",
        "        x = nn.ReLU()(self.seventh_conv(x))\n",
        "        x = self.seventh_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.eighth_conv(x))\n",
        "\n",
        "        x = self.first_drop(x)\n",
        "        x = self.avg_polling(x)\n",
        "\n",
        "        x = x.view(-1, x.shape[1])  # output channel for flatten before entering the dense layer\n",
        "\n",
        "        x = nn.ReLU()(self.first_dense(x))\n",
        "        x = self.second_drop(x)\n",
        "\n",
        "        x = self.second_dense(x)\n",
        "        y = nn.LogSoftmax(dim=1)(x)  # consider using Log-Softmax\n",
        "\n",
        "        return y\n",
        "\n",
        "    def get_epochs(self):\n",
        "        return self.epochs\n",
        "\n",
        "    def get_learning_rate(self):\n",
        "        return self.learning_rate\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batch_size\n",
        "\n",
        "    def train_model(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([2.103336921, 3.203278689, 1])).to(device)\n",
        "\n",
        "        n_total_steps = len(self.dataset.train_loader)\n",
        "\n",
        "        for epoch in range(self.get_epochs()):\n",
        "            for i, (embedding, labels) in enumerate(self.dataset.train_loader):\n",
        "\n",
        "                embedding = embedding.type(torch.FloatTensor)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "            \n",
        "                labels = labels.to(device)\n",
        "                embedding = embedding.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.forward(embedding)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                if i == 74:\n",
        "                    print(f'Epoch [{epoch + 1}/{self.epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpaZ7PlR3CRK"
      },
      "source": [
        "# **TEST**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "oO0UNKVK2-3S"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "classes = {0: 'positive', 1:'neutral', 2:'negative'}\n",
        "\n",
        "class TestConvNet:\n",
        "    def __init__(self, model, dataset):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.results = []\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            n_correct = 0\n",
        "            n_samples = 0\n",
        "            n_class_correct = [0 for i in range(3)]\n",
        "            n_class_samples = [0 for i in range(3)]\n",
        "            predicted = []\n",
        "            n_class = [0 for i in range(len(self.dataset.test_y))]\n",
        "            j = 0\n",
        "            print(len(self.dataset.test_y))\n",
        "            \n",
        "            for embedding, labels in self.dataset.test_loader:\n",
        "                \n",
        "                embedding = embedding.type(torch.FloatTensor)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "                labels = labels.to(device)\n",
        "                embedding = embedding.to(device)\n",
        "                outputs = self.model(embedding)\n",
        "\n",
        "                # max returns (value ,index)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                n_samples += labels.size(0)\n",
        "                n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                for i in range(self.model.batch_size):\n",
        "                    label = labels[i]\n",
        "                    pred = predicted[i]\n",
        "                    if label == pred:\n",
        "                        n_class_correct[label] += 1\n",
        "                    n_class_samples[label] += 1\n",
        "                    n_class[j] = pred.view(-1).detach().cpu().numpy()[0]\n",
        "                    j += 1\n",
        "\n",
        "            acc = 100.0 * n_correct / n_samples\n",
        "            print(f'Accuracy of the network: {acc} %')\n",
        "            self.results.append(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "            for i in range(3):\n",
        "                acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "                print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "                self.results.append(f'Accuracy of {classes[i]}: {acc} %')\n",
        "            \n",
        "            return n_class\n",
        "        # saved_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
        "        # file_name = 'result.txt'\n",
        "        # directory = '/content/data/' + str(saved_time)\n",
        "        # os.mkdir(directory)\n",
        "\n",
        "        # with open(directory + \"/\" + file_name, 'w') as f:\n",
        "        #     for line in self.results:\n",
        "        #         f.write(line)\n",
        "        #         f.write('\\n')\n",
        "\n",
        "        # torch.save(self.model, directory + \"/model.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbdGGMiq35tS"
      },
      "source": [
        "# **Main**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McQMhz2iXxNQ"
      },
      "source": [
        "## NORM AND INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sj2SqEan3-Gz"
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "model = bundle.get_model().to(device)\n",
        "\n",
        "\n",
        "def inference(file_name):\n",
        "    SAMPLE_RATE = 16000\n",
        "    waveform, sample_rate = torchaudio.load(filepath=file_name,  num_frames=SAMPLE_RATE * 3)\n",
        "    waveform = waveform.view(1, 96000)\n",
        "    waveform = waveform.to(device)\n",
        "\n",
        "    if (len(waveform[0]) < 48000):\n",
        "        print(f'less than 3 seconds: {file_name}')\n",
        "\n",
        "    if sample_rate != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        embedding, _ = model(waveform)\n",
        "\n",
        "    return embedding.unsqueeze(0)\n",
        "\n",
        "\n",
        "def Norm(X):\n",
        "    embedding = X.detach().cpu().numpy()\n",
        "    for i in range(len(embedding)):\n",
        "        mlist = embedding[0][i]\n",
        "        embedding[0][i] = 2 * (mlist - np.max(mlist)) / (np.max(mlist) - np.min(mlist)) + 1\n",
        "\n",
        "    return torch.from_numpy(embedding).to(device)\n",
        "\n",
        "\n",
        "def recording(name):\n",
        "    # import sounddevice\n",
        "    # # from scipy.io.wavefile import write\n",
        "    # filename = name\n",
        "    # fps = 16000\n",
        "    # duration = 3\n",
        "    # print(\"Recording ..\")\n",
        "    # recording = sounddevice.rec(int(duration * fps), samplerate = fps, channels = 2)\n",
        "    # sounddevice.wait()\n",
        "    # print(\"Done.\")\n",
        "    # write(filename, fps, recording)\n",
        "    # return filename + \".wav\"\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCDZ2CSE4Mit"
      },
      "source": [
        "## START TRAIN\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOYlypNI4RD2",
        "outputId": "b9fd4e37-c85a-41fd-8157-dc119aae617a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.1073\n",
            "Epoch [2/10], Loss: 1.0354\n",
            "Epoch [3/10], Loss: 1.2364\n",
            "Epoch [4/10], Loss: 0.7706\n",
            "Epoch [5/10], Loss: 0.9073\n",
            "Epoch [6/10], Loss: 0.9123\n",
            "Epoch [7/10], Loss: 0.6203\n",
            "Epoch [8/10], Loss: 0.7558\n",
            "Epoch [9/10], Loss: 0.8923\n",
            "Epoch [10/10], Loss: 0.6020\n"
          ]
        }
      ],
      "source": [
        "aer_dataset = Data()\n",
        "cnn = ConvNet(3, aer_dataset)\n",
        "cnn.to(device)\n",
        "cnn.train_model()\n",
        "torch.save(cnn, \"/model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTWNPkZ04UCp"
      },
      "source": [
        "## START TEST\n",
        "\n",
        "\n",
        "Accuracy of the network: 70.1171875 %\n",
        "\n",
        "Accuracy of positive: 63.80597014925373 %\n",
        "\n",
        "Accuracy of neutral: 55.367231638418076 %\n",
        "\n",
        "Accuracy of negative: 77.54749568221071 %\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md2c1Cu8n2Wv",
        "outputId": "ae1cd44b-146f-4970-a772-c61136fcc4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1048\n",
            "Accuracy of the network: 52.5390625 %\n",
            "Accuracy of positive: 40.44117647058823 %\n",
            "Accuracy of neutral: 76.04790419161677 %\n",
            "Accuracy of negative: 51.452991452991455 %\n"
          ]
        }
      ],
      "source": [
        "test = TestConvNet(cnn, aer_dataset)\n",
        "n_class = test.test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Display the confusion matrix as a heatmap\n",
        "arr = confusion_matrix(aer_dataset.test_y.detach().cpu().numpy(), n_class)\n",
        "class_names = ['Positive', 'Neutral', ' Negative']\n",
        "print(arr)\n",
        "df_cm = pd.DataFrame(arr, class_names, class_names)\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='BuGn')\n",
        "plt.xlabel(\"prediction\")\n",
        "plt.ylabel(\"label (ground truth)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "b3Ok6cs_J9K_",
        "outputId": "14529e25-c464-4206-c2f0-d6388ade1a51"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[117  89  73]\n",
            " [ 18 127  25]\n",
            " [163 135 301]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAF2CAYAAAAcHvCGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxVVf3/8df7XiZlRlBRURBBwnkM0xzTzBzK2dTU/EWl5Ww5lGFlWmaWphR+LdGcZxzTlICcAQcG5wEFURxBEJTh8/tjb+iAdzice/cZ308e+8HZ6+y912fL8Z7PXWvttRQRmJmZWW2qK3UAZmZmVjpOBMzMzGqYEwEzM7Ma5kTAzMyshjkRMDMzq2FOBMzMzGqYEwEzM7MyJamDpCclPStpiqRz0/J+kp6Q9IqkGyW1S8vbp/uvpO/3ba4OJwJmZmbl6zNg14jYDNgc2FPSEOB3wMURsQHwEXBsevyxwEdp+cXpcU1yImBmZlamIjE33W2bbgHsCtySlo8EvpW+3i/dJ31/N0lqqo42rRpxK7r21Wc85aF9waBua5Q6BCtDndqsUuoQrAxt2LVbk1+ArUG7r9Oi76p4cHqzMUqqByYAGwCXAa8CH0fEovSQ6cDa6eu1gbcAImKRpNnAasD7jV3fLQJmZmaFklq0SRoqaXzONnTFKiJicURsDqwDbAsMas1bKNsWATMzs2oXESOAEXke+7Gk0cB2QDdJbdJWgXWAGelhM4A+wHRJbYCuwAdNXdctAmZmZoWqa+HWDEm9JHVLX68C7A48D4wGDkwPOwq4M309Kt0nff/haGZ1QbcImJmZFarpcXitoTcwMh0nUAfcFBF3S5oK3CDpN8DTwJXp8VcC10h6BfgQOLS5CpwImJmZFSrjPCAingO2aKD8NZLxAiuWLwAOWpk63DVgZmZWw9wiYGZmVqjsuwYy50TAzMysUFXQru5EwMzMrFBuETAzM6thlZ8HVEOjhpmZmRXKLQJmZmaFqqv8JgEnAmZmZoWq/DzAiYCZmVnBPFjQzMyshlV+HuDBgmZmZrXMLQJmZmaF8mBBMzOzGlb5eYATATMzs4JVwWBBjxEwMzOrYW4RMDMzK5THCJiZmdWwys8DnAiYmZkVrArGCDgRMDMzK1Tl5wEeLGhmZlbL3CJgZmZWKA8WNDMzq2GVnwc4ETAzMyuYBwuamZnVsCoYaVcFt2BmZmaFcouAmZlZodw1YGZmVsMqPw9wImBmZlawKmgR8BgBMzOzGuYWATMzs0JVwa/TTgTMzMwKVQVdA04EzMzMClX5eUC2jRqSBkp6SNLkdH9TST/Psk4zM7OiqVPLtjKQde/GFcCZwEKAiHgOODTjOs3MzCxPWXcNrBoRT2r5PpRFGddpZmZWHB4j0Kz3JfUHAkDSgcDMjOs0MzMrjsrPAzJPBI4HRgCDJM0AXgcOz7hOMzOzopBbBJo1LSK+JqkjUBcRn2Rcn5mZWdFUQyKQ9WDB1yWNAIYAczOuy8zMzFZS1onAIODfJF0Er0v6i6QdMq7TzMysKKSWbeUg00QgIj6NiJsiYn9gC6ALMCbLOs3MzIqlTmrRVg4yn1lQ0k7AIcCewHjg4KzrNDMzK4ZqGCOQaSIg6Q3gaeAm4PSImJdlfWZmZrZysm4R2DQi5mRcR8UbdfFwXnpyIh27deFHwy8CYOq4xxhz7S2899YM/t/F57HWwP4ATBo9jkdvvWvZue++/iZDL7mANfv3LUXoViT33nAzo++6BwF9+q/PD87+GS9PmsK1fxnOooUL6TdoQ4aeeTr1bbx8SC2ZPm0aF5519rL9d96ewXeGDuWT2bN5Yuw46iS69ujOieecw2q9epUw0upVDS0CiojWv6j004j4vaRLSScTyhURJzR3jWtffab1AytT0yZNpd0qHbjjosuWJQLvvTkd1dVxz6VXsPuxRyxLBHK9+/qb3PTrP/CTv19S7JBLZlC3NUodQtF9+N57nPvDn3DhdSNp1749f/75MDYbsi23/N8/OPuSP9J73T7cfMXf6bnmGuyyzzdLHW5JdGqzSqlDKLnFixdzzDf35g//+DudOndm1U6dALjrxht567XXOe7MM0ocYfFt2LVb5t/Sq5y+VYu+q+ZfOKHkmURWvz48n/49PqPrV5X1NhnMx+/OWq6s17rrNHve5DGPsNFOX8kqLCsjixcv5vPPPqO+vp7PFyygfYcOtGnTlt7r9gFgk2225s5rrq3ZRMDguaeeYs111mH13r2XK18wf375DE+vQtXwnzaTRCAilrZdfxoRN+e+J+mgLOqsRVPHPsYh55xW6jAsYz169eKbhx3CT759MO3at2eTbbdhyG67cP1lf+O1519g/S8N4onRY/hwhWTSasvYBx9kxz32WLZ/zeXDGX3vvazaqRPnDb+8hJFVt2roGsh6HoEz8yyzlTT9hZdp274dq/ddt9ShWMbmzvmECeMe4c+33MBlo27ls/nzeeRfD/LjX53DNZdcxs+P/SGrrLoKdfVZ/+9s5WrhwoU8OXYc2++267KyI4/7EX+/+y522vPr3HPzzU2cbbUuk58ckr6Rjg9YW9IlOdtVNLH6oKShksZLGv/wDbdmEVrVmDL2UTbaeftSh2FFMHn8BFZfqzddunejTZs2bLPzjrw0aQoDN9mIXw6/lN9c+VcGbb4Za/bpU+pQrUQmPPoo/QdtSPfVVvvCezvvuSePPjy6BFHVBkkt2spBVr9CvE0yPmABMCFnGwV8vbGTImJERGwdEVvveugBGYVW+WLJEqaOe4yNd/T4gFrQc43VeXnKVD5bsICIYMr4iazddz1mf/gRAAs//5y7/nk9X/vWviWO1Epl3AMPLNct8Pabby57/cSYsazTd71ShFUT1MI/zV5f6iNptKSpkqZIOjEtHyZphqRn0m2vnHPOlPSKpBclNfqdu1RWYwSeBZ6VdG1ENNoCYIlbf/dnpj03lU/nfMLFR/6InY84iFU6d+K+4f/g09lzuH7Y71hj/fU44jfJY0LTJj9Pl56r0b137Y2gr0UbbDSYL++yE2cd/X3q6+vpO3AAu+63NzeNuJKnH3mMiOBr396XjbbestShWgksmD+fZ554kuPO/F+v68jLLmPGtDdRXR2rr7kmx53xsxJGWN2K8Fv9IuDUiJgoqTMwQdKD6XsXR8QfVohnMHAosBGwFvBvSQMjYnFjFWT1+OBNEXGwpEks//iggIiITZu7Ri09Pmj5q8XHB615fnzQGlKMxwe7nvXlFn1Xzf7tEysVo6Q7gb8A2wNzG0gEzgSIiPPT/X8BwyLiscaumdXjgyemf++d0fXNzMwqnqShwNCcohERMaKRY/uSrNvzBEki8GNJ3yXpij81Ij4C1gYezzltelrWqEzGCETEzPTl+8BbETENaA9sRjJ+wMzMrOK1dNGh3LFx6dZYEtAJuBU4KZ2xdzjQH9gcmAlcVPA9FHpinsYCHSStDTwAHAlclXGdZmZmRVGMpwYktSVJAq6NiNsAIuLdiFgcEUuAK4Bt08NnALmPEK2TljUq60RAEfEpsD9weUQcRDKAwczMrOJlnQgoOehK4PmI+GNOee4Ukt8GJqevRwGHSmovqR8wAHiyqTqyXqFEkrYDDgeOTcvqM67TzMysWmxP0po+SdIzadlZwGGSNicZkP8G8AOAiJgi6SZgKskTB8c39cQAZJ8InEQyk+DtaXDrA57ZwszMqkLWTw9GxH+hwQkH7m3inPOA8/KtI9NEICLGAGMkdZLUKSJeA5pdedDMzKwSlMvsgC2RaSIgaRPgaqBHsqv3gO9GxJQs6zUzMysGJwLN+xtwSkSMBpC0M8noRs+Na2ZmFa8aEoGsnxrouDQJAIiI/wAdM67TzMzM8pR1i8Brkn4BXJPuHwG8lnGdZmZmReEWgeZ9D+gF3EYyGULPtMzMzKziSS3bykEmLQKSOgA/BDYAJpHMgbwwi7rMzMxKpRpaBLLqGhgJLATGAd8AvkQyp4CZmVnVcCLQuMERsQmApCtpZnpDMzMzK42sEoFl3QARsagaMiYzM7MV1VXB91tWicBmkuakrwWsku4LiIjoklG9ZmZmRVMFeUA2iUBEeGEhMzOretXQ4p3144NmZmZWxrKeUMjMzKxqqcGFASuLEwEzM7MCVUPXgBMBMzOzAjkRMDMzq2FVkAd4sKCZmVktc4uAmZlZgdw1YGZmVsOkym9YdyJgZmZWoGpoEaj8VMbMzMwK5hYBMzOzAqmu8n+fdiJgZmZWII8RMDMzq2HVMEbAiYCZmVmBqqFFoPLvwMzMzArmFgEzM7MCuWvAzMyshlVD14ATATMzswK5RcDMzKyGVUOLQOXfgZmZmRXMLQJmZmYFcteAmZlZDauGrgEnAmZmZoWqq/wWgcpPZczMzKxgbhEwMzMrkLsGzMzMapgHC5qZmdUwtwiYmZnVsGpIBCr/DszMzKxgbhEwMzMrkMcImJmZ1bBq6BpwImBmZlYgtwhk6IC+m5Y6BCtDf3/piVKHYGXoqAHbljoEq1HV0CJQ+XdgZmZmBSvbFgEzM7Ny564BMzOzGqa6ym9Yr/w7MDMzKxFJLdryuH4fSaMlTZU0RdKJaXkPSQ9Kejn9u3taLkmXSHpF0nOStmyuDicCZmZm5WsRcGpEDAaGAMdLGgycATwUEQOAh9J9gG8AA9JtKDC8uQqcCJiZmRVIqmvR1pyImBkRE9PXnwDPA2sD+wEj08NGAt9KX+8HXB2Jx4Fukno3VUezYwQkrQ5sD6wFzAcmA+MjYkmzd2BmZlbFijlYUFJfYAvgCWCNiJiZvvUOsEb6em3grZzTpqdlM2lEo4mApF1Imhp6AE8Ds4AOJFlHf0m3ABdFxJyVvx0zM7PK19J5BCQNJWnCX2pERIxo4LhOwK3ASRExJzcBiYiQFIXG0FSLwF7A9yPizQYCagPsDeyeBmZmZlZzWtoikH7pf+GLf4U62pJ8114bEbelxe9K6h0RM9Om/1lp+QygT87p66RljWo0lYmI0xtKAtL3FkXEHRHhJMDMzCwjSjKNK4HnI+KPOW+NAo5KXx8F3JlT/t306YEhwOycLoQG5TNGoD1wANA39/iI+FWe92FmZlaVijDF8PbAkcAkSc+kZWcBFwA3SToWmAYcnL53L0mL/ivAp8AxzVWQz4RCdwKzgQnAZysTvZmZWVXLOBGIiP8CjfU/7NbA8QEcvzJ15JMIrBMRe67MRc3MzGpBrUwx/KikTSJiUubRmJmZVZBqWH2wqccHJwGRHnOMpNdIugZE0vrgdYLNzMwqXFMtAnsXLQozM7MKVFfNXQMRMQ1A0jURcWTue5KuIRnFaGZmVrPU6Di+ypHPGIGNcnck1QNbZROOmZlZ5aiGMQKN3oGkMyV9AmwqaY6kT9L9Wfxv4gIzMzOrYE11DZwPnC/p/Ig4s4gxmZmZVYRaeXzwPkk7rlgYEWMziMfMzKxiqPGG9YqRTyJwes7rDsC2JLMM7ppJRGZmZhWiJloEImKf3H1JfYA/ZRaRmZlZhair5sGCTZgOfKm1AzEzM7Piy2f1wUtJZhiEJHHYHJiYZVBmZmaVoFbmERif83oRcH1EPJJRPGZmZhWjGuYRaDIRSCcP2iMiDi9SPGZmZhWj6gcLRsRiSetJahcRnxcrKDMzs0pQK10DrwGPSBoFzFtaGBF/zCwqMzMzK4p8EoFX060O6JyWReOHm5mZ1YaqHyOQmhoRN+cWSDooo3jMzMwqRl0VdA3kk8o0tM6A1x4wM7OaJ9W1aCsHjbYISPoGsBewtqRLct7qQvIYoZmZmVW4proG3iaZQ2BfkrUFlvoEODnLoMzMzCpBVT8+GBHPAs9Kui4iFhYxJjMzs4pQE6sPOgkwMzNrWFW3CJiZmVnTymXAX0tU/h2YmZlZwZp6auAumpg4KCL2beLcHk1VGhEf5hWdmZlZGav2KYb/kP69P7Am8M90/zDg3WauO4EkiWjov1AA669EjGZmZmWprprHCETEGABJF0XE1jlv3SVpfCOnLT23XyvFZ2ZmVrZq4qkBoKOk9SPiNQBJ/YCO+VYgqTswAOiwtCwixq5soGZmZuWmVp4aOBn4j6TXSJr61wN+kM/FJf0/4ERgHeAZYAjwGLBrQdGamZlZq8pnHoH7JQ0ABqVFL0TEZ3le/0RgG+DxiNhF0iDgt4WFamZmVl6q4fHBfOcR2Aromx6/mSQi4uo8zlsQEQskIal9RLwgacNCgzUzMysn1f7UAACSrgH6kzTtL06LA8gnEZguqRtwB/CgpI+AaQXGamZmVlZqpUVga2BwRDQ6p0BjIuLb6cthkkYDXYH7V/Y6ZmZmlo18EoHJJPMIzFyZC0uqB6ZExCD43+OIZmZm1aKq5xHI0ROYKulJYNkgwaZmFkzfXyzpRUnrRsSbLYzTzMys7NTKPALDWnD97sCUNImYt7SwuSSilp1z9tmMHfMfevTowW2j7gLgheef5zfnDuPzzz6nvk09Z/3iHDbZdNMSR2pZe/DSK3l9/DOs2rULR1xyHgDjrrqB1596hro2bei25urs/pNjad+pIy+MeZQJt9+37Nz3p03nOxcNo9f665UqfMvYOzNncs6ZZ/LBB+8jif0POpjvHHkkf73sL9x+yy10794dgB+fdBI77LhTiaOtXjUxj0ALm/R/0YJza9J+3/4Whx3+Hc4+44xlZRdf9Ad+eNzx7LDjjowbM4Y/XfQHrhyZz1hNq2SDd92BzfbajQf+fMWysnU325jtjzyIuvp6/jvyJp669R52OOpgBu30FQbt9BUA3n/jLe4+/xInAVWuvk0bTv7pT/nS4MHMmzePww86kCHbbQfA4d/9Lt895nsljrA2VMNTA822aUj6RNKcdFsgabGkOXlef6+IGJO7AXu1LOTqttXW29Cla7flyiQxd95cAObOnUuv1VcvRWhWZGtvtCEdOi0/ied6W2xMXX09AGtu2J+5H3xx/a4Xxz3BwK9+uSgxWun06tWLLw0eDEDHjh3pt/76zJo1q8RRWSVqNhGIiM4R0SUiugCrAAcAl+d5/d0bKPvGSsRnwE/POJOLL/wDe+y6Cxdd+HtOOOnkUodkZWDqv8fSd8svdhG9/N8nGPjVISWIyErl7RkzePH559k47TK88brrOPjb32LYz89mzuzZJY6uukl1LdrKwUpFEYk7gK83dZykH0maBAyS9FzO9jowqQXx1qSbbriB0884gwceHs3pPzuDYb/4ealDshJ78uZR1NXXs+FO2y1X/s5Lr9KmfXt6rrdOiSKzYvt03jxOO+lETj3jTDp16sRBhxzKqPv/xQ233kbPXr3444W/L3WIVS2dMK/grRzk0zWwf852oKQLgAXNnHYdsA9wZ/r30m2riDi8ibqGShovafyVV4zI/y6q3F133sFuuyeNK3vsuSeTJzmXqmVTHxrH6+Of5eun/OALP0jcLVBbFi5cyGknncRe39x72c+I1Xr2pL6+nrq6OvY/8CCm+OdFpupa+Kcc5PPUwD45rxcBbwD7NXVCRMwGZkv62QpvdZLUqbHHCSNiBDACYMHiJSs9gVG16rX66ox/6im22XZbnnz8cdZdz4PAatUbE59jwu33ccB5Z9C2ffvl3oslS3j5kSc56LdnlSg6K6aI4Ffn/IJ+66/PEUcfvaz8vffeo1evXgA8/O9/03/AgBJFWBvK5bf6lsjnqYFjWnD9e0imIxbJMsT9gBeBjVpwzar2s9NOZfyTT/Lxxx+z+y4786Mf/5hzzv0Vvz//tyxevJh27dpzzrm/KnWYVgT3XTSc6ZNfYMGcuVx57Ml8+dBvMf7We1i8cBG3//JCIBkwuNuPjgZgxpQX6dyzB13X9GDSWvDMxIncM2oUGwwcyKH7J5O4/vikk7j/3nt56YUXQGKttdbm7GHDShuolT01N3OwpHWAS4Ht06JxwIkRMX2lK5O2BI6LiP/X3LFuEbCG/P2lJ0odgpWhowZsW+oQrAx1bFOf+a/rxz9yQ4u+qy7b/tCSNynk00HxD2AUsFa63ZWWrbSImAi4A9PMzKpCHWrRVg7yGSPQKyJyv/ivknRSPheXdErObh2wJfD2SsRnZmZWtqphjEA+LQIfSDpCUn26HQF8kOf1O+ds7UnGDDQ50NDMzMyKJ58Wge+RjBG4mGTg36NAXgMII+JcAEmrRsSnhQZpZmZWjoqx+qCkvwN7A7MiYuO0bBjwfeC99LCzIuLe9L0zgWOBxcAJEfGvpq7fZCKQLiX820IXCZK0HXAl0AlYV9JmwA8i4rhCrmdmZlZOirT64FXAX4AVF5m5OCL+sFw80mDgUJKn89YC/i1pYEQsbuziTd5BeuJ6ktoVEDjAn0hmIfwgvd6zwI4FXsvMzKys1Ekt2vIREWOBLy4s0rD9gBsi4rOIeB14BWjysZp8ugZeAx6RNIrllxL+Yz4RRcRbKwymaDQrMTMzqyTF6Bpowo8lfRcYD5waER8BawOP5xwzPS1rVD5tGq8Cd6fH5g7+y8dbkr4ChKS2kk4Dns/zXDMzs6qWO7V+ug3N89ThQH9gc2AmcFGhMeQzs+C5hV4c+CHwZ5JsZAbwAHB8C65nZmZWNlr6+GDu1Pored67OTFcQfILOyTftX1yDl0nLWtUs4mApLtInhbINZukKeJvEdHoAkQR8T7Q6CJDZmZmlaxUkwJJ6h0RM9PdbwOT09ejgOsk/ZFksOAA4MmmrpXvGIFewPXp/iHAJ8BA4ArgyAYCPKeJ60VE/DqPes3MzMpaMSYUknQ9sDPQU9J04JfAzpI2J/lF/Q3gBwARMUXSTcBUkoUCj2/qiQHILxH4SkRsk7N/l6SnImIbSVMaOWdeA2UdSZ5rXA1wImBmZpaHiDisgeIrmzj+POC8fK+fTyLQSdK6S5cOlrQuybwAAJ83EsSyQQuSOgMnkkxCdAMtGNBgZmZWTupUlHkEMpVPInAq8F9Jr5IsJ9wPOE5SR2BkYydJ6gGcQjJGYCSwZfpog5mZWVUol4WDWiKfpwbulTQAGJQWvZgzQPBPDZ0j6UJgf5KRkJtExNzWCNbMzKycVPWiQ5J2WPo6naHo2XRbkL7fRdLGjZx+KsloxZ8Db0uak26fSJrTmjdgZmZWKsWYWTBrTbUIHCDp98D9wASShQ06ABsAuwDrkXzhf0FEVH6niZmZWQ1oNBGIiJPTfv4DgIOA3sB8kpkB/xYR/y1OiGZmZuVJ1T5GICI+JJkr4IrihGNmZlY5yqV5vyXyeWrAzMzMGuBEwMzMrIYpr7X7ylvl34GZmZkVrNEWAUn7N3ViRNzW+uGYmZlVjmrvGtinifcCcCJgZmY1rRomFGrq8cFjihmImZlZpamGFoFmxwhIWkPSlZLuS/cHSzo2+9DMzMwsa/kMFrwK+BfJlMEALwEnZRWQmZlZpahDLdrKQT6JQM+IuAlYAhARi4DFmUZlZmZWASS1aCsH+cwjME/SaiQDBJE0BJidaVRmZmYVoE6V/xR+PonAKcAooL+kR4BewIGZRmVmZlYBqn6tAYCImChpJ2BDQMCLEbEw88jMzMwsc80mApI6AMcBO5B0D4yT9NeIWJB1cGZmZuWsGh4fzKdr4GrgE+DSdP87wDUkSxObmZnVrFpJBDaOiME5+6MlTc0qIDMzs0pRE2MEgImShkTE4wCSvgyMzzYsMzOz8lfVLQKSJpGMCWgLPCrpzXR/PeCF4oRnZmZmWWqqRWDvokVhZmZWgVTN8whExLTcfUmrAx0yj8jMzKxClMs0wS2Rz+OD+wIXkaw1MIuka+B5YKNsQzMzMytvdZWfB+S11sCvgSHASxHRD9gNeDzTqMzMzKwo8kkEFkbEB0CdpLqIGA1snXFcZmZmZa9WFh36WFInYCxwraRZwLxswzIzMyt/1TBGIJ8Wgf2A+cDJwP3Aq8A+WQZlZmZWCWqiRSAicn/7H5lhLGZmZhWl2icU+oRkAqEvvAVERHTJLCozMzMriqbmEehczEDMzMwqTTWMEchnsKCZmZk1oFz6+VvCiYCZmVmB3CJgZmZWw6qhRaDyV0swMzOzgpVti8Dx/7261CFYGRrUY71Sh2BlqNM3/LmwL4oHp2deR1U/PmhmZmZN8xgBMzOzGlYFDQIeI2BmZlbL3CJgZmZWII8RMDMzq2HyGAEzM7Pa5RYBMzOzGlYNTw14sKCZmVkNc4uAmZlZgaphimEnAmZmZgWqhjEC7howMzMrkFr4J686pL9LmiVpck5ZD0kPSno5/bt7Wi5Jl0h6RdJzkrZs7vpOBMzMzApUJ7Voy9NVwJ4rlJ0BPBQRA4CH0n2AbwAD0m0oMLzZe8g3CjMzMyu+iBgLfLhC8X7AyPT1SOBbOeVXR+JxoJuk3k1d34mAmZlZgVraIiBpqKTxOdvQPKteIyJmpq/fAdZIX68NvJVz3PS0rFEeLGhmZlagls4sGBEjgBEtvEZIikLPdyJgZmZWoLrSPTTwrqTeETEzbfqflZbPAPrkHLdOWtYodw2YmZlVnlHAUenro4A7c8q/mz49MASYndOF0CC3CJiZmRWoGIsOSboe2BnoKWk68EvgAuAmSccC04CD08PvBfYCXgE+BY5p7vpOBMzMzApUjAmFIuKwRt7arYFjAzh+Za7vRMDMzKxA1TCzoBMBMzOzAhWjayBrHixoZmZWw9wiYGZmViB3DZiZmdUwL0NsZmZWw+qqYIyAEwEzM7MCVUPXgAcLmpmZ1TC3CJiZmRWo8tsDnAiYmZm1QOWnAk4EzMzMClQNTw14jICZmVkNyzQRkLSDpGPS170k9cuyPjMzs2JSC7dykFnXgKRfAlsDGwL/ANoC/wS2z6pOMzOzYqqGtQayHCPwbWALYCJARLwtqXOG9ZmZmRVVFQwRyDQR+DwiQlIASOqYYV1mZmYlUPmZQJZjBG6S9Degm6TvA/8GrsiwPjMzM1tJmbUIRMQfJO0OzCEZJ3BORDyYVX1mZmbF5jECTZB0CnCjv/zNzKxaVX4akO0Ygc7AA5I+BG4Ebo6IdzOsz8zMrKg8oVATIuLciNgIOB7oDYyR9O+s6jMzM7OVV4yZBWcB7wAfAKsXoT4zMzPLU2aJgKTjJP0HeAhYDfh+RGyaVX1mZmbFphb+KQdZjhHoA5wUEXhUoBEAABGOSURBVM9kWIeZmVnJVMMYgVZPBCR1iYg5wIXpfo/c9yPiw9au08zMrBQqPw3IpkXgOmBvYAIQLP/fKYD1M6jTzMzMCtDqiUBE7J3+7ZUGzcysqpVLP39LZDlY8KF8yszMzKx0shgj0AFYFegpqTv/6xroAqzd2vWZmZmVigcLNuwHwEnAWiTjBJb+V5oD/CWD+szMzEqiGroGshgj8Gfgz5J+EhGXtvb1q9FLV93DR5NeoW3nVdly2PeXlb/98Hhmjp6A6urovkl/+h24K5+8/javXHMfkIy8XHefHei5xYYlityyNPayq3lzwiRW6dqZAy4+B4Dx149i2lPPojqxSpfO7Pjjo+jYoxtvT36RB38/nM6r9wSg75e3YMuDvlnK8C0D7du2Z+wfb6V923a0qa/nlnH3Muzqi+i7Zh9uOOtyVuvSnQkvP8eRvzuRhYsW8tVNvsyffjSMTdf/Eoeedzy3jrun1LdgZSjL1QcvlbQxMBjokFN+dVZ1Vqo1vrIJa+2yFS/9465lZR+/MI0PnnmZLc45lrq2bfh8zjwAVl2rF5uffQyqr+Pzj+fy9K+vZLVNB6D6YkwSacU0YJftGPyNnRlz6VXLyjbdb3e2PmxfACbf8zBP33wPO/zgcADWHDSAr591fClCtSL5bOFn7Hr6wcxb8Clt6tvw34tv576nRnPKAd/n4tuu4Mb/jGL4iedz7J6H8te7r+HNWTM4+sJTOO2gH5Q69KpV+e0B2Q4W/CVwabrtAvwe2Der+ipZ14Hr0qZjh+XK3hkzkT57DqGubZKrtevSEYD69m2XfekvWbSouIFaUfUePID2nVZdrqzdqqsse73os8+hCvonbeXMW/ApAG3btKFtmzZEBLtuvj23jE1+2x/5wM18a/uvAzDt3elMev15lsSSksVb9aSWbWUgy5kFDwQ2A56OiGMkrQH8M8P6qsr8dz9k9itv8cYdY6hr24Z+B+1K575rAfDJazN4eeS9LPhwNgO/t49bA2rMU9fdwStjnqDdqquw17CTl5XPeuk1bjv116zavRtfPuoAuvdZq4RRWlbq6uqYcPl9bLBWXy4bNZJX336Dj+fOYfGSxQBMf38ma6+2ZomjrB3l8VXeMll+g8yPiCXAIkldSBYf6tPUCZKGShovafwLd/0nw9DKXyxZwqJ5C9jszKPod+CuvPC3O4gIADqvvzZbnvt9Nj/raKbf9xhLFrploJZs851vcdjfzqf/V7dl6v3/AaDn+uty6PDz2P+iX7DRXjvz4O+GlzZIy8ySJUvY4odfZ53DtmHbDTdnUJ8NSh2SVbgsE4HxkroBV5A8PTAReKypEyJiRERsHRFbD9pn5wxDK3/tundmtS02RBKd+62FJBbNnb/cMav27kl9+3bMm/FeiaK0Utrgq9vyxuNPA0mXQdtVku6lPltuwpLFi1kwZ24pw7OMzZ43h9HPPsp2g7eiW6cu1NfVA7BOz97M+OCdEkdXO6ph0aHMEoGIOC4iPo6IvwK7A0dFxDFZ1VdtVtt8ILNfnAbA/Hc/YMnixbTptAoL3v+YWJz09y34YDbz3/mADqt1LWWoVkSzZ7677PW0p56l69prAPDpR7OXtRjNevl1IoL2nTuWJEbLTs+uPejasQsAHdp1YPctv8rzb77M6Gcf5cAdk6dEjtrjIO589IFShllTqiER0NIfHq1+YWnLBopnA9Miotm27GPHXJVNYGXohSvuYPaLb7Jo7nzadunIuvt+ldWHbMzLI+9h3lvvovp6+h20K90G9WXWY5OYfv/jybgAiXX33oHVthhY6lsomkE91it1CEXz8MX/x8wpL7Hgk7ms0rULWx2yD29NnMzst98FiU69erDD0O/QcbXuTLlvNM//ayx19XXUt2vHkKMOZI1B/Ut9C0Xz01OOLHUIRbFJvy8x8qcXU19XT53ETWPv5tf//BP91lyXG86+nB6du/H0q5M54oIT+Hzh52w9cDNuH/Z/dO/UlQULP+OdD2ex8fd3K/VtFE08OD3zb9o35s5r0XdV304dS54NZJkIPA5sCTxHMp5iY2AK0BX4UUQ0mbLWUiJg+aulRMDyVyuJgK2c4iQCn7YwEVi15IlAlmME3ga2SPv8twK2AF4j6Sb4fYb1mpmZWZ6yfHxwYERMWboTEVMlDYqI16phbmYzM7Nq+DbLMhGYImk4cEO6fwgwVVJ7YGGG9ZqZmRVFNfxim2UicDRwHMkCRACPAKeRJAG7ZFivmZlZUZTLyP+WyHKtgfmSLgfujogXV3jbDzibmVnFq/w0INu1BvYFngHuT/c3lzQqq/rMzMxs5WX51MAvgW2BjwEi4hmgX4b1mZmZFZlauJVelmMEFkbE7BUGUnhuADMzqxpVMFYw86cGvgPUSxoAnAA8mmF9ZmZmRVUNgwWz7Br4CbAR8BlwPTCH/z1BYGZmZnmQ9IakSZKekTQ+Lesh6UFJL6d/dy/0+lkuOvRpRJwdEdukswueHRELsqrPzMysiu0SEZtHxNbp/hnAQxExAHgo3S9Iq3cNSPoHjY8FiIg4trXrNDMzK4USdgzsB+ycvh4J/Af4WSEXymKMwN0NlPUBTgbqM6jPzMysJIo0WDCAByQF8LeIGAGsEREz0/ffAdYo9OKtnghExK1LX0taHzgL2BG4ALiyteszMzOrVJKGAkNzikakX/S5doiIGZJWBx6U9ELumxERaZJQkEyeGpA0CPg5yYqDFwI/jIhFWdRlZmZWqdIv/RW/+Fc8Zkb69yxJt5PM0fOupN4RMVNSb2BWoTG0+mBBSTcD9wKPkfRfjAK6pCMce7R2fWZmZqWiFv5p9vpSR0mdl74G9gAmk3y3HpUedhRwZ6H3kEWLwDYk/RmnAaemZUvvNoD1M6jTzMysGq0B3J5OztcGuC4i7pf0FHCTpGOBacDBhVaQxRiBvq19TTMzs3KU9WDBiHgN2KyB8g+A3VqjjiwnFDIzM7My50TAzMyshmW51oCZmVlVq/yVBpwImJmZFawaEgF3DZiZmdUwJwJmZmY1zF0DZmZmBSrSWgOZciJgZmZWsMrPBJwImJmZFajy0wCPETAzM6tpTgTMzMxqmLsGzMzMClQNXQNOBMzMzApUDU8NuGvAzMyshrlFwMzMrEBV0CDgFgEzM7Na5kTAzMyshrlrwMzMrECqgtGCbhEwMzOrYU4EzMzMapi7BszMzApU+R0DbhEwMzOraW4RMDMzK1A1tAg4ETAzMytQFTw04K4BMzOzWuZEwMzMrIa5a8DMzKxAVdAz4ETAzMyscJWfCjgRMDMzK5AHC5qZmVlFcyJgZmZWw9w1YGZmVqAq6BlAEVHqGKwZkoZGxIhSx2HlxZ8La4g/F7ay3DVQGYaWOgArS/5cWEP8ubCV4kTAzMyshjkRMDMzq2FOBCqD+/usIf5cWEP8ubCV4sGCZmZmNcwtAmZmZjXMiUCGJC2W9IykyZJulrTqSp6/lqRb0tebS9or5719JZ3R2jFbcUgKSRfl7J8maViB1+om6bgCz31DUs9CzrXWkf4b3Jqzf6CkqzKo56Tcn0GS7pXUrbXrscrjRCBb8yNi84jYGPgc+OHKnBwRb0fEgenu5sBeOe+NiogLWi9UK7LPgP1b6Uu4G9BgIiDJk4ZVhq0kDc64jpOAZYlAROwVER9nXKdVACcCxTMO2EBSD0l3SHpO0uOSNgWQtFPaevCMpKcldZbUN21NaAf8Cjgkff8QSUdL+oukrpKmSapLr9NR0luS2krqL+l+SRMkjZM0qIT3b8tbRDKo6+QV35DUS9Ktkp5Kt+3T8mGSTss5brKkvsAFQP/0s3GhpJ3Tf+9RwNT02DvSz8EUSX7OvPxcBJy9YmH6//PfJT2Z/lzYLy1fVdJNkqZKul3SE5K2Tt8bLml8+m99blp2ArAWMFrS6LTsDUk9JV0g6ficOpd9ziSdnn4Gn1t6Las+TgSKIP2t7BvAJOBc4OmI2BQ4C7g6Pew04PiI2Bz4KjB/6fkR8TlwDnBj2sJwY857s4FngJ3Sor2Bf0XEQpIvmp9ExFbp9S/P7i6tAJcBh0vqukL5n4GLI2Ib4ADg/5q5zhnAq+ln4/S0bEvgxIgYmO5/L/0cbA2cIGm11rkFayU3AVtK2mCF8rOBhyNiW2AX4EJJHUlagD6KiMHAL4Ctcs+JiK2BTYGdJG0aEZcAbwO7RMQuK9RxI3Bwzv7BwI2S9gAGANuStEhuJWnH1rhZKy9uNszWKpKeSV+PA64EniD54U5EPCxpNUldgEeAP0q6FrgtIqYr//UtbwQOAUYDhwKXS+oEfAW4Oec67VvhnqyVRMQcSVcDJ5CT+AFfAwbn/Lt1Sf89V8aTEfF6zv4Jkr6dvu5D8gP+gwLCtmwsBi4EzgTuyynfA9g3pyWoA7AusANJwkhETJb0XM45B6etPm2A3sBgIPf95UTE05JWl7QW0IskwXhL0olp/U+nh3Yi+dyMbdGdWtlxIpCt+elv+Ms09uUeERdIuodkHMAjkr4OLMiznlHAbyX1IPnN4GGgI/DxivVb2fkTMBH4R05ZHTAkIpb795e0iOVb8To0cd15OeftTJJcbBcRn0r6TzPnWmlcQ5IITM4pE3BARLyYe2BjP0ck9SNp/dsmIj5KBx3m8299M3AgsCbJLxZL6z4/Iv62EvdgFchdA8U3Djgclv2Afj/9zbB/REyKiN8BTwEr9ud/AnRu6IIRMTc958/A3RGxOCLmAK9LOiitS5I2y+SOrGAR8SFJs/CxOcUPAD9ZuiNpaTL3BkmTP5K2BPql5Y1+NlJdSX7L+zQdJzKkVYK3VpV2513M8uNG/gX8ROk3v6Qt0vJHSJvz00GGm6TlXUiSwNmS1iDpklyqqc/JjSStiQeSJAVL6/7e0tYoSWtLWr3gG7Sy5USg+IaR9LU9RzLI66i0/KR08NdzwEKWbx6EpNl/8NLBgg1c90bgCP6XzUOScBwr6VlgCrBf692GtaKLgNynB04Atk4HaE3lf0+b3Ar0kDQF+DHwEkBEfEDSijRZ0oUNXP9+oI2k50k+c49ndB/WcleyfEvtr4G2wHPpv/uv0/LLgV7p5+M3JP9/z46IZ0ma8l8AriNJGJYaAdy/dLBgroiYQpIkzIiImWnZA+k1HpM0CbiFphNOq1CeWdDMrMJIqgfaRsQCSf2BfwMbpgOLzVaKxwiYmVWeVUkeBWxL0pd/nJMAK5RbBMzMzGqYxwiYmZnVMCcCZmZmNcyJgJmZWQ1zImBWAdL1A+5OXze58qRWWI1QOatYmpmtyIMFzUpIUn1ELM7juJ2B0yJi7zyO7UsysdTGLQ7QzKqeWwTMMqJk9cgXJF0r6XlJt6Srxr0h6XeSJgIHSdpD0mOSJkq6OWcmtz3T8ycC++dc92hJf0lfr5GuPvdsun2FL65G2FfS5PT4DpL+IWmSktXsdsm55m1KVqt8WdLvi/3fy8xKw4mAWbY2BC6PiC8Bc0hWjQP4ICK2JJkI5ufA19L98cApkjoAVwD7kKwfsWYj178EGBMRm5FMPzyFhlcjXOp4ICJiE+AwYGRaFyQrzB1CMl3tIZL6tPDezawCOBEwy9ZbEbF0mtd/kqwaB/+bCnoIyepwj6QrVR4FrEey1sTrEfFyJP13/2zk+rsCwwHSNSZmNxPPDkuvFREvANOApUsVPxQRs9PFjqamcZhZlfPMgmbZWnEQztL9pasDCngwIg7LPShnoaFi+izn9WL888GsJrhFwCxb60raLn39HeC/K7z/OLC9pA0AJHWUNJBk0Zi+6TzykDTjN+Qh4EfpufWSutL0KnO5q18OJFnb/sVGjjWzGuBEwCxbLwLHpyv/dSdtxl8qIt4DjgauT1eefAwYlDbPDwXuSQcLzmrk+icCu6Srw00ABjezGuHlQF16/I3A0RHxGWZWs/z4oFlG/BifmVUCtwiYmZnVMLcImJmZ1TC3CJiZmdUwJwJmZmY1zImAmZlZDXMiYGZmVsOcCJiZmdUwJwJmZmY17P8Di6pUXBE+7bsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awUU1AREn3fk"
      },
      "source": [
        "## INFERENCE\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH-sKsHj4ZwS",
        "outputId": "8f624e50-d86b-4e60-8e10-0cc5d79a1a54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([9.8371655e-01, 6.2508939e-04, 1.5658503e-02], dtype=float32)]\n",
            "positive\n"
          ]
        }
      ],
      "source": [
        "inf_X = inference('/content/data/MyDrive/dl/angry2.wav')\n",
        "X = Norm(inf_X)\n",
        "y = cnn.forward(X)\n",
        "y = y.cpu().detach().numpy()\n",
        "predict = [np.exp(c) for c in y]\n",
        "max = np.argmax(predict)\n",
        "print(predict)\n",
        "print(classes[max])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "train_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}