{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorAzaria/Sentiment-Analysis-Deep-Learning-Methods-For-Speech-Recognition/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685hzZYY0Oua",
        "outputId": "67a3e9aa-a48b-40bd-a898-9d2be607f8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/data/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/data/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3h7Ml8w1u_g"
      },
      "source": [
        "# **IMPORTS**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jCj-OhuD1uyS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "import torchaudio\n",
        "from numpy import mat\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "!sudo apt-get install libportaudio2\n",
        "!sudo apt-get install python-scipy\n",
        "\n",
        "!pip install sounddevice\n",
        "!pip install scipy\n",
        "\n",
        "import sounddevice\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS4QYGCi02Y7"
      },
      "source": [
        "# **PREPROCESS**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "820sVvYW1E5o"
      },
      "outputs": [],
      "source": [
        "class Data:\n",
        "\n",
        "    def __init__(self):\n",
        "        file_handler = open('/content/data/MyDrive/dl/dataset5.pth', 'rb')\n",
        "        self.data = pickle.load(file_handler)\n",
        "        x_dataset = [embedding[1] for embedding in self.data]\n",
        "        y_dataset = [label[2] for label in self.data]\n",
        "        train_x, test_x, train_y, test_y = train_test_split(np.array(x_dataset), np.array(y_dataset), test_size=0.30)\n",
        "        self.train_x = torch.from_numpy(train_x)\n",
        "        self.train_y = torch.from_numpy(train_y)\n",
        "        torch_train = TensorDataset(self.train_x, self.train_y)\n",
        "        \n",
        "        self.test_x = torch.from_numpy(test_x)\n",
        "        self.test_y = torch.from_numpy(test_y)\n",
        "        torch_test = TensorDataset(self.test_x, self.test_y)\n",
        "        \n",
        "\n",
        "        self.train_loader = DataLoader(torch_train, batch_size=32, drop_last=True, shuffle=True)\n",
        "        self.test_loader = DataLoader(torch_test, batch_size=32, drop_last=True, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9NoyVXt2F_6"
      },
      "source": [
        "# **TRAIN**\n",
        "\n",
        "1, 149, 32\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "56-6NfI62iiW"
      },
      "outputs": [],
      "source": [
        "DROP_OUT = 0.5\n",
        "NUM_OF_CLASSES = 3\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_of_classes, dataset):\n",
        "        super().__init__()\n",
        "\n",
        "        # Hyper parameters\n",
        "        self.epochs = 300\n",
        "        self.batch_size = 32\n",
        "        self.learning_rate = 0.0001\n",
        "        self.dataset = dataset\n",
        "\n",
        "        # Model Architecture\n",
        "        self.first_conv = nn.Conv2d(1, 96, kernel_size=(5, 5), padding=1) # (96, 147, 30)\n",
        "        self.first_bn = nn.BatchNorm2d(96)\n",
        "        self.first_polling = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2)) # (96, 73, 14)\n",
        "\n",
        "        self.second_conv = nn.Conv2d(96, 256, kernel_size=(5, 5), padding=1) # (256, 71, 12)\n",
        "        self.second_bn = nn.BatchNorm2d(256)\n",
        "        self.second_polling = nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1)) # (256, 69, 10)\n",
        "\n",
        "        self.third_conv = nn.Conv2d(256, 384, kernel_size=(3, 3), padding=1) # (384, 69, 10 )\n",
        "        self.third_bn = nn.BatchNorm2d(384)\n",
        "\n",
        "        self.forth_conv = nn.Conv2d(384, 256, kernel_size=(3, 3), padding=1) # (256, 69, 10)\n",
        "        self.forth_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.fifth_conv = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1) # (256, 69, 10)\n",
        "        self.fifth_bn = nn.BatchNorm2d(256)\n",
        "        self.fifth_polling = nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1)) # (256, 68, 9)\n",
        "\n",
        "        self.sixth_conv = nn.Conv2d(256, 64, kernel_size=(2, 2), padding=1) # (64, 69, 10)\n",
        "\n",
        "        self.seventh_conv = nn.Conv2d(64, 64, kernel_size=(3,3), padding=1) # (64, 69, 10)\n",
        "        self.seventh_polling = nn.MaxPool2d(kernel_size=(2,2), stride=(2, 2)) # (64, 34, 5)\n",
        "\n",
        "        self.eighth_conv = nn.Conv2d(64, 32, kernel_size=(3,3), padding=1) # (32, 34, 5)\n",
        "        self.first_drop = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.avg_polling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.first_dense = nn.Linear(32, 1024)\n",
        "        self.second_drop = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.second_dense = nn.Linear(1024, num_of_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        x = nn.ReLU()(self.first_conv(X))\n",
        "        x = self.first_bn(x)\n",
        "        x = self.first_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.second_conv(x))\n",
        "        x = self.second_bn(x)\n",
        "        x = self.second_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.third_conv(x))\n",
        "        x = self.third_bn(x)\n",
        "\n",
        "        x = nn.ReLU()(self.forth_conv(x))\n",
        "        x = self.forth_bn(x)\n",
        "\n",
        "        x = nn.ReLU()(self.fifth_conv(x))\n",
        "        x = self.fifth_bn(x)\n",
        "        x = self.fifth_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.sixth_conv(x))\n",
        "\n",
        "        x = nn.ReLU()(self.seventh_conv(x))\n",
        "        x = self.seventh_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.eighth_conv(x))\n",
        "\n",
        "        x = self.first_drop(x)\n",
        "        x = self.avg_polling(x)\n",
        "\n",
        "        x = x.view(-1, x.shape[1])  # output channel for flatten before entering the dense layer\n",
        "\n",
        "        x = nn.ReLU()(self.first_dense(x))\n",
        "        x = self.second_drop(x)\n",
        "\n",
        "        x = self.second_dense(x)\n",
        "        y = nn.LogSoftmax(dim=1)(x)  # consider using Log-Softmax\n",
        "\n",
        "        return y\n",
        "\n",
        "    def get_epochs(self):\n",
        "        return self.epochs\n",
        "\n",
        "    def get_learning_rate(self):\n",
        "        return self.learning_rate\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batch_size\n",
        "    \n",
        "    def train_model(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n",
        "        # [3304, 2895, 9004] --> 15k examples\n",
        "        # [1184, 688, 2363] --> 4235 examples\n",
        "        # criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([2.72518159806, 3.11018998273, 1])).to(device)\n",
        "        criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.99, 5.43, 1])).to(device)\n",
        "\n",
        "        n_total_steps = len(self.dataset.train_loader)\n",
        "\n",
        "        for epoch in range(self.get_epochs()):\n",
        "            for i, (embedding, labels) in enumerate(self.dataset.train_loader):\n",
        "\n",
        "                embedding = embedding.type(torch.FloatTensor)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "            \n",
        "                labels = labels.to(device)\n",
        "                embedding = embedding.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.forward(embedding)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                if i == 74:\n",
        "                    print(f'Epoch [{epoch + 1}/{self.epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpaZ7PlR3CRK"
      },
      "source": [
        "# **TEST**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oO0UNKVK2-3S"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "classes = {0: 'positive', 1:'neutral', 2:'negative'}\n",
        "\n",
        "class TestConvNet:\n",
        "    def __init__(self, model, dataset):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.results = []\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            n_correct = 0\n",
        "            n_samples = 0\n",
        "            n_class_correct = [0 for i in range(3)]\n",
        "            n_class_samples = [0 for i in range(3)]\n",
        "            \n",
        "            n_class = [0 for i in range(len(self.dataset.test_y))]\n",
        "            j = 0\n",
        "            \n",
        "            \n",
        "            for embedding, labels in self.dataset.test_loader:\n",
        "                \n",
        "                embedding = embedding.type(torch.FloatTensor)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "                labels = labels.to(device)\n",
        "                embedding = embedding.to(device)\n",
        "                outputs = self.model(embedding)\n",
        "\n",
        "                # max returns (value ,index)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                n_samples += labels.size(0)\n",
        "                n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                for i in range(self.model.batch_size):\n",
        "                    label = labels[i]\n",
        "                    pred = predicted[i]\n",
        "                    if label == pred:\n",
        "                        n_class_correct[label] += 1\n",
        "                    n_class_samples[label] += 1\n",
        "                    n_class[j] = pred.view(-1).detach().cpu().numpy()[0]\n",
        "                    j += 1\n",
        "\n",
        "            acc = 100.0 * n_correct / n_samples\n",
        "            print(f'Accuracy of the network: {acc} %')\n",
        "            self.results.append(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "            for i in range(3):\n",
        "                acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "                print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "                self.results.append(f'Accuracy of {classes[i]}: {acc} %')\n",
        "            \n",
        "            return n_class\n",
        "        # saved_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
        "        # file_name = 'result.txt'\n",
        "        # directory = '/content/data/' + str(saved_time)\n",
        "        # os.mkdir(directory)\n",
        "\n",
        "        # with open(directory + \"/\" + file_name, 'w') as f:\n",
        "        #     for line in self.results:\n",
        "        #         f.write(line)\n",
        "        #         f.write('\\n')\n",
        "\n",
        "        # torch.save(self.model, directory + \"/model.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbdGGMiq35tS"
      },
      "source": [
        "# **Main**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McQMhz2iXxNQ"
      },
      "source": [
        "## NORM AND INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "sj2SqEan3-Gz"
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "model = bundle.get_model().to(device)\n",
        "\n",
        "\n",
        "def inference(file_name):\n",
        "    SAMPLE_RATE = 16000\n",
        "    waveform, sample_rate = torchaudio.load(filepath=file_name,  num_frames=SAMPLE_RATE * 3)\n",
        "    waveform = waveform.view(1, 96000)\n",
        "    waveform = waveform.to(device)\n",
        "    \n",
        "    if (len(waveform[0]) < 48000):\n",
        "        print(f'less than 3 seconds: {file_name}')\n",
        "\n",
        "    if sample_rate != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        embedding, _ = model(waveform)\n",
        "\n",
        "    return embedding.unsqueeze(0)\n",
        "\n",
        "\n",
        "def Norm(X):\n",
        "    embedding = X.detach().cpu().numpy()\n",
        "    for i in range(len(embedding)):\n",
        "        mlist = embedding[0][i]\n",
        "        embedding[0][i] = 2 * (mlist - np.max(mlist)) / (np.max(mlist) - np.min(mlist)) + 1\n",
        "\n",
        "    return torch.from_numpy(embedding).to(device)\n",
        "\n",
        "def format_float(num):\n",
        "    return np.format_float_positional(num, trim='-')\n",
        "\n",
        "def recording(name):\n",
        "    # import sounddevice\n",
        "    # # from scipy.io.wavefile import write\n",
        "    # filename = name\n",
        "    # fps = 16000\n",
        "    # duration = 3\n",
        "    # print(\"Recording ..\")\n",
        "    # recording = sounddevice.rec(int(duration * fps), samplerate = fps, channels = 2)\n",
        "    # sounddevice.wait()\n",
        "    # print(\"Done.\")\n",
        "    # write(filename, fps, recording)\n",
        "    # return filename + \".wav\"\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCDZ2CSE4Mit"
      },
      "source": [
        "## START TRAIN\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOYlypNI4RD2"
      },
      "outputs": [],
      "source": [
        "aer_dataset = Data()\n",
        "cnn = ConvNet(3, aer_dataset)\n",
        "cnn.to(device)\n",
        "cnn.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn, \"/content/data/MyDrive/dl/model100.pth\")"
      ],
      "metadata": {
        "id": "JEZvqhOZbHFl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTWNPkZ04UCp"
      },
      "source": [
        "## START TEST\n",
        "\n",
        "\n",
        "Accuracy of the network: 76.20192307692308 %\n",
        "\n",
        "Accuracy of positive: 65.60693641618496 %\n",
        "\n",
        "Accuracy of neutral: 71.14427860696517 %\n",
        "\n",
        "Accuracy of negative: 82.88159771754636 %\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md2c1Cu8n2Wv",
        "outputId": "e2edde02-daf2-402b-c732-30d868b3c105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network: 76.28205128205128 %\n",
            "Accuracy of positive: 81.08108108108108 %\n",
            "Accuracy of neutral: 71.42857142857143 %\n",
            "Accuracy of negative: 75.50143266475645 %\n"
          ]
        }
      ],
      "source": [
        "test = TestConvNet(cnn, aer_dataset)\n",
        "n_class = test.test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Display the confusion matrix as a heatmap\n",
        "arr = confusion_matrix(aer_dataset.test_y.detach().cpu().numpy(), n_class)\n",
        "class_names = ['Positive', 'Neutral', ' Negative']\n",
        "print(arr)\n",
        "df_cm = pd.DataFrame(arr, class_names, class_names)\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='BuGn')\n",
        "plt.xlabel(\"prediction\")\n",
        "plt.ylabel(\"label (ground truth)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "b3Ok6cs_J9K_",
        "outputId": "95c1a4e3-418e-4662-c63f-9f64b06cfadd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[275  24  39]\n",
            " [ 27 155  41]\n",
            " [125  58 527]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awUU1AREn3fk"
      },
      "source": [
        "## INFERENCE\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results(y):\n",
        "  predict = [np.exp(c) for c in y]\n",
        "  max = np.argmax(predict)\n",
        "  print(f'Predicted: {classes[max]}')\n",
        "  print(f'Positive: {round(predict[0][0]*100, 4)}%')\n",
        "  print(f'Neutral: {round(predict[0][1]*100, 4)}%')\n",
        "  print(f'Negative: {round(predict[0][2]*100, 4)}%')"
      ],
      "metadata": {
        "id": "Ph6iOQImBFJF"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH-sKsHj4ZwS",
        "outputId": "e975ec46-4649-47b8-fd94-cc44db705a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: positive\n",
            "Positive: 93.3399%\n",
            "Neutral: 0.2565%\n",
            "Negative: 6.4036%\n"
          ]
        }
      ],
      "source": [
        "inf_X = inference('/content/data/MyDrive/dl/EMOVO/positive/gio-f1-l4.wav')\n",
        "X = Norm(inf_X)\n",
        "y = cnn.forward(X)\n",
        "y = y.cpu().detach().numpy()\n",
        "print_results(y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "train_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}