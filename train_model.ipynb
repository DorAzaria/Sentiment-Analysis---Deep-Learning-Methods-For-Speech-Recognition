{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c98eeb71be0944139f18e34aab5ded4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff2f1f33675a4c5a91e6e41d944083f5",
              "IPY_MODEL_e7a8288e72a0432c9726745831e924b5",
              "IPY_MODEL_daaec26061794daea2ef384eca9df530"
            ],
            "layout": "IPY_MODEL_0cbcef7a0b6d45c695e52bdc25db81a5"
          }
        },
        "ff2f1f33675a4c5a91e6e41d944083f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_300819c40d8549cf8bb5a06ad08e989a",
            "placeholder": "​",
            "style": "IPY_MODEL_6255ae5b17604b6cbb392639fbb4c48a",
            "value": "100%"
          }
        },
        "e7a8288e72a0432c9726745831e924b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_125b33bdb33e4cfa821dffb556cd6ddf",
            "max": 377664473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a54d61cbab5149bb855f8062004fb68f",
            "value": 377664473
          }
        },
        "daaec26061794daea2ef384eca9df530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077ffa58f7e74bbf81696ca80b5a6776",
            "placeholder": "​",
            "style": "IPY_MODEL_b9f49e261a464528add7e2012e752c36",
            "value": " 360M/360M [00:05&lt;00:00, 87.2MB/s]"
          }
        },
        "0cbcef7a0b6d45c695e52bdc25db81a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300819c40d8549cf8bb5a06ad08e989a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6255ae5b17604b6cbb392639fbb4c48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "125b33bdb33e4cfa821dffb556cd6ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a54d61cbab5149bb855f8062004fb68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "077ffa58f7e74bbf81696ca80b5a6776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f49e261a464528add7e2012e752c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorAzaria/Sentiment-Analysis-Deep-Learning-Methods-For-Speech-Recognition/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "685hzZYY0Oua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28eb4239-77ac-4338-e3b3-caf6f85b3037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/data/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/data/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTS**\n",
        "---"
      ],
      "metadata": {
        "id": "W3h7Ml8w1u_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "import torchaudio\n",
        "from numpy import mat\n",
        "\n",
        "!sudo apt-get install libportaudio2\n",
        "!sudo apt-get install python-scipy\n",
        "\n",
        "!pip install sounddevice\n",
        "!pip install scipy\n",
        "\n",
        "import sounddevice\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "jCj-OhuD1uyS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPROCESS**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lS4QYGCi02Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Data:\n",
        "\n",
        "    def __init__(self):\n",
        "        file_handler = open('/content/data/MyDrive/dl/dataset.pth', 'rb')\n",
        "        data = pickle.load(file_handler)\n",
        "        x_dataset = [embedding[1] for embedding in data]\n",
        "        y_dataset = [label[2] for label in data]\n",
        "        train_x, test_x, train_y, test_y = train_test_split(np.array(x_dataset), np.array(y_dataset), test_size=0.30)\n",
        "        train_x = torch.from_numpy(train_x)\n",
        "        train_y = torch.from_numpy(train_y)\n",
        "        torch_train = TensorDataset(train_x, train_y)\n",
        "        \n",
        "        self.test_x = torch.from_numpy(test_x)\n",
        "        test_y = torch.from_numpy(test_y)\n",
        "        torch_test = TensorDataset(self.test_x, test_y)\n",
        "        \n",
        "\n",
        "        self.train_loader = DataLoader(torch_train, batch_size=32, drop_last=True, shuffle=True)\n",
        "        self.test_loader = DataLoader(torch_test, batch_size=32, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "id": "820sVvYW1E5o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAIN**\n",
        "\n",
        "1, 149, 32\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "I9NoyVXt2F_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DROP_OUT = 0.5\n",
        "NUM_OF_CLASSES = 3\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_of_classes, dataset):\n",
        "        super().__init__()\n",
        "\n",
        "        # Hyper parameters\n",
        "        self.epochs = 300\n",
        "        self.batch_size = 32\n",
        "        self.learning_rate = 0.0001\n",
        "        self.dataset = dataset\n",
        "\n",
        "        # Model Architecture\n",
        "        self.first_conv = nn.Conv2d(1, 96, kernel_size=(5, 5), padding=1) # (96, 147, 30)\n",
        "        self.first_bn = nn.BatchNorm2d(96)\n",
        "        self.first_polling = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2)) # (96, 73, 14)\n",
        "\n",
        "        self.second_conv = nn.Conv2d(96, 256, kernel_size=(5, 5), padding=1) # (256, 71, 12)\n",
        "        self.second_bn = nn.BatchNorm2d(256)\n",
        "        self.second_polling = nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1)) # (256, 69, 10)\n",
        "\n",
        "        self.third_conv = nn.Conv2d(256, 384, kernel_size=(3, 3), padding=1) # (384, 69, 10 )\n",
        "        self.third_bn = nn.BatchNorm2d(384)\n",
        "\n",
        "        self.forth_conv = nn.Conv2d(384, 256, kernel_size=(3, 3), padding=1) # (256, 69, 10)\n",
        "        self.forth_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.fifth_conv = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1) # (256, 69, 10)\n",
        "        self.fifth_bn = nn.BatchNorm2d(256)\n",
        "        self.fifth_polling = nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1)) # (256, 68, 9)\n",
        "\n",
        "        self.sixth_conv = nn.Conv2d(256, 64, kernel_size=(2, 2), padding=1) # (64, 69, 10)\n",
        "\n",
        "        self.seventh_conv = nn.Conv2d(64, 64, kernel_size=(3,3), padding=1) # (64, 69, 10)\n",
        "        self.seventh_polling = nn.MaxPool2d(kernel_size=(2,2), stride=(2, 2)) # (64, 34, 5)\n",
        "\n",
        "        self.eighth_conv = nn.Conv2d(64, 32, kernel_size=(3,3), padding=1) # (32, 34, 5)\n",
        "        self.first_drop = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.avg_polling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.first_dense = nn.Linear(32, 1024)\n",
        "        self.second_drop = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.second_dense = nn.Linear(1024, num_of_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        x = nn.ReLU()(self.first_conv(X))\n",
        "        x = self.first_bn(x)\n",
        "        x = self.first_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.second_conv(x))\n",
        "        x = self.second_bn(x)\n",
        "        x = self.second_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.third_conv(x))\n",
        "        x = self.third_bn(x)\n",
        "\n",
        "        x = nn.ReLU()(self.forth_conv(x))\n",
        "        x = self.forth_bn(x)\n",
        "\n",
        "        x = nn.ReLU()(self.fifth_conv(x))\n",
        "        x = self.fifth_bn(x)\n",
        "        x = self.fifth_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.sixth_conv(x))\n",
        "\n",
        "        x = nn.ReLU()(self.seventh_conv(x))\n",
        "        x = self.seventh_polling(x)\n",
        "\n",
        "        x = nn.ReLU()(self.eighth_conv(x))\n",
        "\n",
        "        x = self.first_drop(x)\n",
        "        x = self.avg_polling(x)\n",
        "\n",
        "        x = x.view(-1, x.shape[1])  # output channel for flatten before entering the dense layer\n",
        "\n",
        "        x = nn.ReLU()(self.first_dense(x))\n",
        "        x = self.second_drop(x)\n",
        "\n",
        "        x = self.second_dense(x)\n",
        "        y = nn.LogSoftmax(dim=1)(x)  # consider using Log-Softmax\n",
        "\n",
        "        return y\n",
        "\n",
        "    def get_epochs(self):\n",
        "        return self.epochs\n",
        "\n",
        "    def get_learning_rate(self):\n",
        "        return self.learning_rate\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batch_size\n",
        "\n",
        "    def train_model(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([2.103336921, 3.203278689, 1])).to(device)\n",
        "\n",
        "        n_total_steps = len(self.dataset.train_loader)\n",
        "\n",
        "        for epoch in range(self.get_epochs()):\n",
        "            for i, (embedding, labels) in enumerate(self.dataset.train_loader):\n",
        "\n",
        "                embedding = embedding.type(torch.FloatTensor)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "            \n",
        "                labels = labels.to(device)\n",
        "                embedding = embedding.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.forward(embedding)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                if i == 74:\n",
        "                    print(f'Epoch [{epoch + 1}/{self.epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "56-6NfI62iiW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TEST**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fpaZ7PlR3CRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "classes = {0: 'positive', 1:'neutral', 2:'negative'}\n",
        "\n",
        "class TestConvNet:\n",
        "    def __init__(self, model, dataset):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.results = []\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            n_correct = 0\n",
        "            n_samples = 0\n",
        "            n_class_correct = [0 for i in range(3)]\n",
        "            n_class_samples = [0 for i in range(3)]\n",
        "            for embedding, labels in self.dataset.test_loader:\n",
        "                \n",
        "                embedding = embedding.type(torch.FloatTensor)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "                labels = labels.to(device)\n",
        "                embedding = embedding.to(device)\n",
        "                outputs = self.model(embedding)\n",
        "\n",
        "                # max returns (value ,index)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                n_samples += labels.size(0)\n",
        "                n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                for i in range(self.model.batch_size):\n",
        "                    label = labels[i]\n",
        "                    pred = predicted[i]\n",
        "                    if label == pred:\n",
        "                        n_class_correct[label] += 1\n",
        "                    n_class_samples[label] += 1\n",
        "\n",
        "            acc = 100.0 * n_correct / n_samples\n",
        "            print(f'Accuracy of the network: {acc} %')\n",
        "            self.results.append(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "            for i in range(3):\n",
        "                acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "                print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "                self.results.append(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n",
        "        # saved_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
        "        # file_name = 'result.txt'\n",
        "        # directory = '/content/data/' + str(saved_time)\n",
        "        # os.mkdir(directory)\n",
        "\n",
        "        # with open(directory + \"/\" + file_name, 'w') as f:\n",
        "        #     for line in self.results:\n",
        "        #         f.write(line)\n",
        "        #         f.write('\\n')\n",
        "\n",
        "        # torch.save(self.model, directory + \"/model.pth\")\n"
      ],
      "metadata": {
        "id": "oO0UNKVK2-3S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "FbdGGMiq35tS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NORM AND INFERENCE"
      ],
      "metadata": {
        "id": "McQMhz2iXxNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "model = bundle.get_model().to(device)\n",
        "\n",
        "\n",
        "def inference(file_name):\n",
        "    SAMPLE_RATE = 16000\n",
        "    waveform, sample_rate = torchaudio.load(filepath=file_name,  num_frames=SAMPLE_RATE * 3)\n",
        "    waveform = waveform.view(1, 96000)\n",
        "    waveform = waveform.to(device)\n",
        "\n",
        "    if (len(waveform[0]) < 48000):\n",
        "        print(f'less than 3 seconds: {file_name}')\n",
        "\n",
        "    if sample_rate != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        embedding, _ = model(waveform)\n",
        "\n",
        "    return embedding.unsqueeze(0)\n",
        "\n",
        "\n",
        "def Norm(X):\n",
        "    embedding = X.detach().cpu().numpy()\n",
        "    for i in range(len(embedding)):\n",
        "        mlist = embedding[0][i]\n",
        "        embedding[0][i] = 2 * (mlist - np.max(mlist)) / (np.max(mlist) - np.min(mlist)) + 1\n",
        "\n",
        "    return torch.from_numpy(embedding).to(device)\n",
        "\n",
        "\n",
        "def recording(name):\n",
        "    # import sounddevice\n",
        "    # # from scipy.io.wavefile import write\n",
        "    # filename = name\n",
        "    # fps = 16000\n",
        "    # duration = 3\n",
        "    # print(\"Recording ..\")\n",
        "    # recording = sounddevice.rec(int(duration * fps), samplerate = fps, channels = 2)\n",
        "    # sounddevice.wait()\n",
        "    # print(\"Done.\")\n",
        "    # write(filename, fps, recording)\n",
        "    # return filename + \".wav\"\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "sj2SqEan3-Gz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "c98eeb71be0944139f18e34aab5ded4a",
            "ff2f1f33675a4c5a91e6e41d944083f5",
            "e7a8288e72a0432c9726745831e924b5",
            "daaec26061794daea2ef384eca9df530",
            "0cbcef7a0b6d45c695e52bdc25db81a5",
            "300819c40d8549cf8bb5a06ad08e989a",
            "6255ae5b17604b6cbb392639fbb4c48a",
            "125b33bdb33e4cfa821dffb556cd6ddf",
            "a54d61cbab5149bb855f8062004fb68f",
            "077ffa58f7e74bbf81696ca80b5a6776",
            "b9f49e261a464528add7e2012e752c36"
          ]
        },
        "outputId": "2e88dd47-3f7c-4371-84dd-f019eae16098"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/360M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c98eeb71be0944139f18e34aab5ded4a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## START TRAIN\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MCDZ2CSE4Mit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aer_dataset = Data()\n",
        "cnn = ConvNet(3, aer_dataset)\n",
        "cnn.to(device)\n",
        "cnn.train_model()\n",
        "torch.save(cnn, \"/model.pth\")"
      ],
      "metadata": {
        "id": "SOYlypNI4RD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b568a5-c34e-42cd-9232-33b9219c313e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/300], Loss: 1.0663\n",
            "Epoch [2/300], Loss: 1.0597\n",
            "Epoch [3/300], Loss: 1.0638\n",
            "Epoch [4/300], Loss: 0.8417\n",
            "Epoch [5/300], Loss: 0.9038\n",
            "Epoch [6/300], Loss: 0.7894\n",
            "Epoch [7/300], Loss: 0.8518\n",
            "Epoch [8/300], Loss: 1.1682\n",
            "Epoch [9/300], Loss: 0.6890\n",
            "Epoch [10/300], Loss: 0.9722\n",
            "Epoch [11/300], Loss: 0.6835\n",
            "Epoch [12/300], Loss: 0.7361\n",
            "Epoch [13/300], Loss: 0.6986\n",
            "Epoch [14/300], Loss: 0.6237\n",
            "Epoch [15/300], Loss: 0.4312\n",
            "Epoch [16/300], Loss: 0.5533\n",
            "Epoch [17/300], Loss: 0.4099\n",
            "Epoch [18/300], Loss: 0.4972\n",
            "Epoch [19/300], Loss: 0.5994\n",
            "Epoch [20/300], Loss: 0.6270\n",
            "Epoch [21/300], Loss: 0.4116\n",
            "Epoch [22/300], Loss: 0.4055\n",
            "Epoch [23/300], Loss: 0.6152\n",
            "Epoch [24/300], Loss: 0.4963\n",
            "Epoch [25/300], Loss: 0.4077\n",
            "Epoch [26/300], Loss: 0.4712\n",
            "Epoch [27/300], Loss: 0.4583\n",
            "Epoch [28/300], Loss: 0.5656\n",
            "Epoch [29/300], Loss: 0.5132\n",
            "Epoch [30/300], Loss: 0.3766\n",
            "Epoch [31/300], Loss: 0.5859\n",
            "Epoch [32/300], Loss: 0.5955\n",
            "Epoch [33/300], Loss: 0.3031\n",
            "Epoch [34/300], Loss: 0.4759\n",
            "Epoch [35/300], Loss: 0.4381\n",
            "Epoch [36/300], Loss: 0.5780\n",
            "Epoch [37/300], Loss: 0.4824\n",
            "Epoch [38/300], Loss: 0.7921\n",
            "Epoch [39/300], Loss: 0.6273\n",
            "Epoch [40/300], Loss: 0.6154\n",
            "Epoch [41/300], Loss: 0.4925\n",
            "Epoch [42/300], Loss: 0.3251\n",
            "Epoch [43/300], Loss: 0.4999\n",
            "Epoch [44/300], Loss: 0.2924\n",
            "Epoch [45/300], Loss: 0.5828\n",
            "Epoch [46/300], Loss: 0.4494\n",
            "Epoch [47/300], Loss: 0.6358\n",
            "Epoch [48/300], Loss: 0.3476\n",
            "Epoch [49/300], Loss: 0.4841\n",
            "Epoch [50/300], Loss: 0.5943\n",
            "Epoch [51/300], Loss: 0.6529\n",
            "Epoch [52/300], Loss: 0.5292\n",
            "Epoch [53/300], Loss: 0.6969\n",
            "Epoch [54/300], Loss: 0.3666\n",
            "Epoch [55/300], Loss: 0.4315\n",
            "Epoch [56/300], Loss: 0.4528\n",
            "Epoch [57/300], Loss: 0.3779\n",
            "Epoch [58/300], Loss: 0.2657\n",
            "Epoch [59/300], Loss: 0.4190\n",
            "Epoch [60/300], Loss: 0.4671\n",
            "Epoch [61/300], Loss: 0.4271\n",
            "Epoch [62/300], Loss: 0.5087\n",
            "Epoch [63/300], Loss: 0.2109\n",
            "Epoch [64/300], Loss: 0.3262\n",
            "Epoch [65/300], Loss: 0.1852\n",
            "Epoch [66/300], Loss: 0.4135\n",
            "Epoch [67/300], Loss: 0.2813\n",
            "Epoch [68/300], Loss: 0.4561\n",
            "Epoch [69/300], Loss: 0.3294\n",
            "Epoch [70/300], Loss: 0.4204\n",
            "Epoch [71/300], Loss: 0.4980\n",
            "Epoch [72/300], Loss: 0.4670\n",
            "Epoch [73/300], Loss: 0.3796\n",
            "Epoch [74/300], Loss: 0.4771\n",
            "Epoch [75/300], Loss: 0.4267\n",
            "Epoch [76/300], Loss: 0.3403\n",
            "Epoch [77/300], Loss: 0.3536\n",
            "Epoch [78/300], Loss: 0.4591\n",
            "Epoch [79/300], Loss: 0.3333\n",
            "Epoch [80/300], Loss: 0.4679\n",
            "Epoch [81/300], Loss: 0.0652\n",
            "Epoch [82/300], Loss: 0.2236\n",
            "Epoch [83/300], Loss: 0.2234\n",
            "Epoch [84/300], Loss: 0.2485\n",
            "Epoch [85/300], Loss: 0.2136\n",
            "Epoch [86/300], Loss: 0.2516\n",
            "Epoch [87/300], Loss: 0.3806\n",
            "Epoch [88/300], Loss: 0.3749\n",
            "Epoch [89/300], Loss: 0.3862\n",
            "Epoch [90/300], Loss: 0.1597\n",
            "Epoch [91/300], Loss: 0.2558\n",
            "Epoch [92/300], Loss: 0.3219\n",
            "Epoch [93/300], Loss: 0.2953\n",
            "Epoch [94/300], Loss: 0.2717\n",
            "Epoch [95/300], Loss: 0.3015\n",
            "Epoch [96/300], Loss: 0.5207\n",
            "Epoch [97/300], Loss: 0.1767\n",
            "Epoch [98/300], Loss: 0.3513\n",
            "Epoch [99/300], Loss: 0.2991\n",
            "Epoch [100/300], Loss: 0.1476\n",
            "Epoch [101/300], Loss: 0.3576\n",
            "Epoch [102/300], Loss: 0.3300\n",
            "Epoch [103/300], Loss: 0.3157\n",
            "Epoch [104/300], Loss: 0.1834\n",
            "Epoch [105/300], Loss: 0.3259\n",
            "Epoch [106/300], Loss: 0.4959\n",
            "Epoch [107/300], Loss: 0.2542\n",
            "Epoch [108/300], Loss: 0.3705\n",
            "Epoch [109/300], Loss: 0.2536\n",
            "Epoch [110/300], Loss: 0.2471\n",
            "Epoch [111/300], Loss: 0.3144\n",
            "Epoch [112/300], Loss: 0.3576\n",
            "Epoch [113/300], Loss: 0.1465\n",
            "Epoch [114/300], Loss: 0.3520\n",
            "Epoch [115/300], Loss: 0.2131\n",
            "Epoch [116/300], Loss: 0.1062\n",
            "Epoch [117/300], Loss: 0.2711\n",
            "Epoch [118/300], Loss: 0.1306\n",
            "Epoch [119/300], Loss: 0.4466\n",
            "Epoch [120/300], Loss: 0.3580\n",
            "Epoch [121/300], Loss: 0.0767\n",
            "Epoch [122/300], Loss: 0.3073\n",
            "Epoch [123/300], Loss: 0.3638\n",
            "Epoch [124/300], Loss: 0.1459\n",
            "Epoch [125/300], Loss: 0.1653\n",
            "Epoch [126/300], Loss: 0.2424\n",
            "Epoch [127/300], Loss: 0.0645\n",
            "Epoch [128/300], Loss: 0.1758\n",
            "Epoch [129/300], Loss: 0.0958\n",
            "Epoch [130/300], Loss: 0.2369\n",
            "Epoch [131/300], Loss: 0.3221\n",
            "Epoch [132/300], Loss: 0.1596\n",
            "Epoch [133/300], Loss: 0.3987\n",
            "Epoch [134/300], Loss: 0.1644\n",
            "Epoch [135/300], Loss: 0.1227\n",
            "Epoch [136/300], Loss: 0.1740\n",
            "Epoch [137/300], Loss: 0.0837\n",
            "Epoch [138/300], Loss: 0.2311\n",
            "Epoch [139/300], Loss: 0.1815\n",
            "Epoch [140/300], Loss: 0.5679\n",
            "Epoch [141/300], Loss: 0.1887\n",
            "Epoch [142/300], Loss: 0.3446\n",
            "Epoch [143/300], Loss: 0.2098\n",
            "Epoch [144/300], Loss: 0.1479\n",
            "Epoch [145/300], Loss: 0.1242\n",
            "Epoch [146/300], Loss: 0.1312\n",
            "Epoch [147/300], Loss: 0.0570\n",
            "Epoch [148/300], Loss: 0.0777\n",
            "Epoch [149/300], Loss: 0.0543\n",
            "Epoch [150/300], Loss: 0.0920\n",
            "Epoch [151/300], Loss: 0.1938\n",
            "Epoch [152/300], Loss: 0.1955\n",
            "Epoch [153/300], Loss: 0.2237\n",
            "Epoch [154/300], Loss: 0.0974\n",
            "Epoch [155/300], Loss: 0.0479\n",
            "Epoch [156/300], Loss: 0.3289\n",
            "Epoch [157/300], Loss: 0.0862\n",
            "Epoch [158/300], Loss: 0.2435\n",
            "Epoch [159/300], Loss: 0.1423\n",
            "Epoch [160/300], Loss: 0.3142\n",
            "Epoch [161/300], Loss: 0.0549\n",
            "Epoch [162/300], Loss: 0.4793\n",
            "Epoch [163/300], Loss: 0.1131\n",
            "Epoch [164/300], Loss: 0.2163\n",
            "Epoch [165/300], Loss: 0.2696\n",
            "Epoch [166/300], Loss: 0.1329\n",
            "Epoch [167/300], Loss: 0.0825\n",
            "Epoch [168/300], Loss: 0.1199\n",
            "Epoch [169/300], Loss: 0.0351\n",
            "Epoch [170/300], Loss: 0.0760\n",
            "Epoch [171/300], Loss: 0.1199\n",
            "Epoch [172/300], Loss: 0.0623\n",
            "Epoch [173/300], Loss: 0.1189\n",
            "Epoch [174/300], Loss: 0.1353\n",
            "Epoch [175/300], Loss: 0.1050\n",
            "Epoch [176/300], Loss: 0.0922\n",
            "Epoch [177/300], Loss: 0.0876\n",
            "Epoch [178/300], Loss: 0.2510\n",
            "Epoch [179/300], Loss: 0.1308\n",
            "Epoch [180/300], Loss: 0.0493\n",
            "Epoch [181/300], Loss: 0.0378\n",
            "Epoch [182/300], Loss: 0.0544\n",
            "Epoch [183/300], Loss: 0.0880\n",
            "Epoch [184/300], Loss: 0.0498\n",
            "Epoch [185/300], Loss: 0.1561\n",
            "Epoch [186/300], Loss: 0.0987\n",
            "Epoch [187/300], Loss: 0.1108\n",
            "Epoch [188/300], Loss: 0.1179\n",
            "Epoch [189/300], Loss: 0.0521\n",
            "Epoch [190/300], Loss: 0.0128\n",
            "Epoch [191/300], Loss: 0.1043\n",
            "Epoch [192/300], Loss: 0.1719\n",
            "Epoch [193/300], Loss: 0.2424\n",
            "Epoch [194/300], Loss: 0.0494\n",
            "Epoch [195/300], Loss: 0.1725\n",
            "Epoch [196/300], Loss: 0.0833\n",
            "Epoch [197/300], Loss: 0.0344\n",
            "Epoch [198/300], Loss: 0.0477\n",
            "Epoch [199/300], Loss: 0.0898\n",
            "Epoch [200/300], Loss: 0.1228\n",
            "Epoch [201/300], Loss: 0.0153\n",
            "Epoch [202/300], Loss: 0.0775\n",
            "Epoch [203/300], Loss: 0.5202\n",
            "Epoch [204/300], Loss: 0.1206\n",
            "Epoch [205/300], Loss: 0.1375\n",
            "Epoch [206/300], Loss: 0.1115\n",
            "Epoch [207/300], Loss: 0.0013\n",
            "Epoch [208/300], Loss: 0.0871\n",
            "Epoch [209/300], Loss: 0.0926\n",
            "Epoch [210/300], Loss: 0.0876\n",
            "Epoch [211/300], Loss: 0.0073\n",
            "Epoch [212/300], Loss: 0.0594\n",
            "Epoch [213/300], Loss: 0.0138\n",
            "Epoch [214/300], Loss: 0.0392\n",
            "Epoch [215/300], Loss: 0.0147\n",
            "Epoch [216/300], Loss: 0.0414\n",
            "Epoch [217/300], Loss: 0.1544\n",
            "Epoch [218/300], Loss: 0.1383\n",
            "Epoch [219/300], Loss: 0.0579\n",
            "Epoch [220/300], Loss: 0.3105\n",
            "Epoch [221/300], Loss: 0.0859\n",
            "Epoch [222/300], Loss: 0.1272\n",
            "Epoch [223/300], Loss: 0.1048\n",
            "Epoch [224/300], Loss: 0.1141\n",
            "Epoch [225/300], Loss: 0.0784\n",
            "Epoch [226/300], Loss: 0.0919\n",
            "Epoch [227/300], Loss: 0.1192\n",
            "Epoch [228/300], Loss: 0.0044\n",
            "Epoch [229/300], Loss: 0.0370\n",
            "Epoch [230/300], Loss: 0.1855\n",
            "Epoch [231/300], Loss: 0.1071\n",
            "Epoch [232/300], Loss: 0.0044\n",
            "Epoch [233/300], Loss: 0.0287\n",
            "Epoch [234/300], Loss: 0.0587\n",
            "Epoch [235/300], Loss: 0.0136\n",
            "Epoch [236/300], Loss: 0.0540\n",
            "Epoch [237/300], Loss: 0.0184\n",
            "Epoch [238/300], Loss: 0.1119\n",
            "Epoch [239/300], Loss: 0.0375\n",
            "Epoch [240/300], Loss: 0.2645\n",
            "Epoch [241/300], Loss: 0.0558\n",
            "Epoch [242/300], Loss: 0.0490\n",
            "Epoch [243/300], Loss: 0.0048\n",
            "Epoch [244/300], Loss: 0.1323\n",
            "Epoch [245/300], Loss: 0.1142\n",
            "Epoch [246/300], Loss: 0.0218\n",
            "Epoch [247/300], Loss: 0.0295\n",
            "Epoch [248/300], Loss: 0.0914\n",
            "Epoch [249/300], Loss: 0.0595\n",
            "Epoch [250/300], Loss: 0.0994\n",
            "Epoch [251/300], Loss: 0.1062\n",
            "Epoch [252/300], Loss: 0.1112\n",
            "Epoch [253/300], Loss: 0.1530\n",
            "Epoch [254/300], Loss: 0.0566\n",
            "Epoch [255/300], Loss: 0.0172\n",
            "Epoch [256/300], Loss: 0.1631\n",
            "Epoch [257/300], Loss: 0.0841\n",
            "Epoch [258/300], Loss: 0.0003\n",
            "Epoch [259/300], Loss: 0.0226\n",
            "Epoch [260/300], Loss: 0.2601\n",
            "Epoch [261/300], Loss: 0.0722\n",
            "Epoch [262/300], Loss: 0.0100\n",
            "Epoch [263/300], Loss: 0.0120\n",
            "Epoch [264/300], Loss: 0.0139\n",
            "Epoch [265/300], Loss: 0.0524\n",
            "Epoch [266/300], Loss: 0.1052\n",
            "Epoch [268/300], Loss: 0.0233\n",
            "Epoch [269/300], Loss: 0.1344\n",
            "Epoch [270/300], Loss: 0.1488\n",
            "Epoch [271/300], Loss: 0.0248\n",
            "Epoch [272/300], Loss: 0.0367\n",
            "Epoch [273/300], Loss: 0.1035\n",
            "Epoch [274/300], Loss: 0.0423\n",
            "Epoch [275/300], Loss: 1.1059\n",
            "Epoch [276/300], Loss: 0.2585\n",
            "Epoch [277/300], Loss: 0.0213\n",
            "Epoch [278/300], Loss: 0.0588\n",
            "Epoch [279/300], Loss: 0.1152\n",
            "Epoch [280/300], Loss: 0.0189\n",
            "Epoch [281/300], Loss: 0.0524\n",
            "Epoch [282/300], Loss: 0.0206\n",
            "Epoch [283/300], Loss: 0.0686\n",
            "Epoch [284/300], Loss: 0.0497\n",
            "Epoch [285/300], Loss: 0.1109\n",
            "Epoch [286/300], Loss: 0.0026\n",
            "Epoch [287/300], Loss: 0.0024\n",
            "Epoch [288/300], Loss: 0.0268\n",
            "Epoch [289/300], Loss: 0.0201\n",
            "Epoch [290/300], Loss: 0.0562\n",
            "Epoch [291/300], Loss: 0.0590\n",
            "Epoch [292/300], Loss: 0.0481\n",
            "Epoch [293/300], Loss: 0.2132\n",
            "Epoch [294/300], Loss: 0.0644\n",
            "Epoch [295/300], Loss: 0.0110\n",
            "Epoch [296/300], Loss: 0.3507\n",
            "Epoch [297/300], Loss: 0.0194\n",
            "Epoch [298/300], Loss: 0.0092\n",
            "Epoch [299/300], Loss: 0.0621\n",
            "Epoch [300/300], Loss: 0.0874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## START TEST\n",
        "\n",
        "\n",
        "Accuracy of the network: 70.1171875 %\n",
        "\n",
        "Accuracy of positive: 63.80597014925373 %\n",
        "\n",
        "Accuracy of neutral: 55.367231638418076 %\n",
        "\n",
        "Accuracy of negative: 77.54749568221071 %\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LTWNPkZ04UCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = TestConvNet(cnn, aer_dataset)\n",
        "test.test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md2c1Cu8n2Wv",
        "outputId": "5c4de576-4dc9-42ed-cd42-f34a47263c2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network: 70.1171875 %\n",
            "Accuracy of positive: 63.80597014925373 %\n",
            "Accuracy of neutral: 55.367231638418076 %\n",
            "Accuracy of negative: 77.54749568221071 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INFERENCE\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "awUU1AREn3fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inf_X = inference('/content/data/MyDrive/dl/angry2.wav')\n",
        "X = Norm(inf_X)\n",
        "y = cnn.forward(X)\n",
        "y = y.cpu().detach().numpy()\n",
        "predict = [np.exp(c) for c in y]\n",
        "max = np.argmax(predict)\n",
        "print(predict)\n",
        "print(classes[max])"
      ],
      "metadata": {
        "id": "oH-sKsHj4ZwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f624e50-d86b-4e60-8e10-0cc5d79a1a54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([9.8371655e-01, 6.2508939e-04, 1.5658503e-02], dtype=float32)]\n",
            "positive\n"
          ]
        }
      ]
    }
  ]
}